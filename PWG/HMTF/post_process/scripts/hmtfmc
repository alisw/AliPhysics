#! /usr/bin/python2
"""
Generate a pdf comparing the plots from two different input files
"""

import argparse
import os
import re
import sys

from rootpy import log, ROOT
from rootpy.io import root_open

from hmtfmc.plotting import Plotting
from hmtfmc import utils, compare
from hmtfmc import roofie

log = log["/hmtfmc"]  # set name of this script in logger


class formatter_class(argparse.ArgumentDefaultsHelpFormatter,
                      argparse.RawTextHelpFormatter):
    pass

parser = argparse.ArgumentParser(formatter_class=formatter_class)
parser.add_argument(
    '-v', '--verbose', action='store_true', default=False)
subparsers = parser.add_subparsers()


############
# Settings #
############

# A list of the estimators which will be included in the plots (if available in the input file)
considered_ests = [
    'EtaLt05',
    'EtaLt08',
    'EtaLt15',
    'Eta08_15',
    'V0M',
    # 'V0A',
    'V0C',
    'ZDC',
    'nMPI',
    'Q2',
    'spherocity',
    'sphericity'
]

# Considered triggers
considered_triggers = [
    'Inel',
    'InelGt0',
    'V0AND'
]

# Ranges of percentiles which should be considered in the plots These
# ranges are then translated into ranges of bins in multiplicity, nMPI
# or whatever is applicable
std_perc_bins = [(1, 0.7), (.5, .4), (.1, .05), (0.001, 0.0)]
percentile_bins = {
    'EtaLt05': std_perc_bins,
    'EtaLt08': std_perc_bins,
    'EtaLt15': std_perc_bins,
    'Eta08_15': std_perc_bins,
    'V0M': std_perc_bins,
    'V0A': std_perc_bins,
    'V0C': std_perc_bins,
    'ZDC': [(1, 0.7), (.7, .3), (.3, .05), (0.001, 0.0)],
    'nMPI': [(1, 0.7), (.7, .4), (.3, .05), (0.001, 0.0)],
    'Q2': [(1, 0.7), (.7, .4), (.3, .05), (0.001, 0.0)],
    'spherocity': [(1, 0.7), (.7, .4), (.3, .05), (0.001, 0.0)],
    'sphericity': [(1, 0.7), (.7, .4), (.3, .05), (0.001, 0.0)],
}


def prepare_plots(args):
    ROOT.gROOT.SetBatch(True)
    train_number = re.match(r'.*/(\d*)_', args.input_file).groups()[-1]
    local_path = os.path.abspath(os.path.join("./", train_number + '_' + os.path.basename(args.input_file)))
    utils.download_file(args.input_file, local_path)
    print "Copied {0} to {1}".format(args.input_file, local_path)

    for global_trigger in considered_triggers:
        sums_dir_name = "Sums" + global_trigger
        results_dir_name = "results_post" + global_trigger

        plotting = Plotting(f_name=local_path, sums_dir_name=sums_dir_name, results_dir_name=results_dir_name,
                            percentile_bins=percentile_bins, considered_ests=considered_ests)

        # call Plotting's memberfunctions to create the desired plots:
        plotting.plot_dNdetas(ratio_to_mb=False)
        plotting.plot_dNdetas(ratio_to_mb=True)
        plotting.plot_PNch_summary()
        plotting.plot_PNch()
        plotting.plot_mult_vs_pt()
        plotting.plot_meanpt_vs_ref_mult_for_pids()
        plotting.plot_pt_distribution_ratios()
        plotting.plot_pid_ratio_vs_refmult()
        plotting.plot_dNdpT(pid_selection='ch')
        plotting.plot_dNdpT(pid_selection='p')
        plotting.plot_dNdpT(pid_selection='pi')
        plotting.plot_dNdpT(pid_selection='K')
        plotting.plot_pT_HM_div_pt_MB(scale_nMPI=False)
        plotting.plot_pT_HM_div_pt_MB(scale_nMPI=True)
        plotting.plot_nMPI_vs_Nch()

description = "Prepare the plots and save the in the input file. This step needs to be taken before creating any PDFs"
parser_prepare_plots = subparsers.add_parser('prepare_plots', description=description)
parser_prepare_plots.add_argument('input_file', type=str, help="Path to file containing the input data")
parser_prepare_plots.set_defaults(op=prepare_plots)


def summary(args):
    ROOT.gROOT.SetBatch(True)

    for global_trigger in considered_triggers:
        with root_open(args.input_file, "read") as f:
            results_dir_name = "results_post" + global_trigger

            latexdoc = roofie.Beamerdoc(author="HMTF (Christian Bourjau)",
                                        title=r"{0} {1}".format(args.gen_name, global_trigger))

            # Fish the plots we want out of the .root file and if necessary adjust some visual settings
            sec = latexdoc.add_section(r"Highlights")

            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__("EtaLt15").__getattr__('dNdeta_summary')
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__("V0M").__getattr__('dNdeta_summary')
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__("EtaLt15").__getattr__('dNdeta_MB_ratio_summary')
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__("V0M").__getattr__('dNdeta_MB_ratio_summary')
            sec.add_figure(c)

            # this plot needs extra massaging, we import it to a roofie figure
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__('PNch_summary')
            fig_all = roofie.Figure()
            fig_sub = roofie.Figure()
            fig_all.import_plottables_from_canvas(c)
            # filter out an reduced set of estimators
            for p in fig_all._plottables:
                if p['legend_title'] in [r'|#eta|#leq1.5', 'ZDC', 'V0M']:
                    fig_sub.add_plottable(p['p'], p['legend_title'])
            # configure the plot
            fig_sub.xtitle = fig_all.xtitle
            fig_sub.ytitle = fig_all.ytitle
            fig_sub.plot.logy = True
            fig_sub.legend.position = 'tr'
            sec.add_figure(fig_sub)

            c = f.MultEstimators.__getattr__(results_dir_name).EtaLt15.dNchdpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).EtaLt15.dNpdpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).EtaLt15.dNpidpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).EtaLt15.dNKdpT
            sec.add_figure(c)

            c = f.MultEstimators.__getattr__(results_dir_name).V0M.dNchdpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).V0M.dNpdpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).V0M.dNpidpT
            sec.add_figure(c)
            c = f.MultEstimators.__getattr__(results_dir_name).V0M.dNKdpT
            sec.add_figure(c)

            # "Backup section with __all__ plots
            sec = latexdoc.add_section(r"$dN/d\eta$")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est).__getattr__('dNdeta_summary')
                except AttributeError:
                    # This happens if the estimator does not exist or if
                    # the plot is not present for this estimator
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$dN/d\eta$ over MB result")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est).__getattr__('dNdeta_MB_ratio_summary')
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$P(N_{ch})$ summary of estimators")
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__('PNch_summary')
            sec.add_figure(c)

            sec = latexdoc.add_section(r"$P(N_{ch}^{\text{estimator 1}})$ binned in $N_{ch}^{\text{estimator 1}}$")
            # The naming convention in this case is a bit confusion. There are essentially two canvas name patterns
            # with the same content. Hence, two canvases
            for est1 in considered_ests:
                for est2 in considered_ests:
                    try:
                        c1 = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est1)\
                            .__getattr__("PNchEst_binned_in_Nch{0}".format(est2))
                        c2 = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est1)\
                            .__getattr__("PNch{0}_binned_in_NchEst".format(est2))
                    except AttributeError:
                        continue
                    for c in [c1, c2]:
                        sec.add_figure(c)

            sec = latexdoc.add_section(r"$\left< p_T \right>$ vs. ref multiplicity")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est).__getattr__('mean_pt')
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"Ratios for various species vs $p_T$")
            for est in considered_ests:
                try:
                    est_dir = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est)
                    canvas_names = [p for p in est_dir.pid_ratios.walk()][-1][-1]
                except AttributeError:
                        continue
                for canvas_name in canvas_names:
                    try:
                        c = est_dir.__getattr__('pid_ratios').__getattr__(canvas_name)
                    except AttributeError:
                        continue
                    sec.add_figure(c)

            sec = latexdoc.add_section(r"Ratios for various species vs ref. multiplicity")
            try:
                ratios_dir = f.MultEstimators.__getattr__(results_dir_name).__getattr__('pid_ratios_vs_refmult')
                canvas_names = [p for p in ratios_dir.walk()][-1][-1]
            except AttributeError:
                    continue
            for canvas_name in canvas_names:
                try:
                    c = ratios_dir.__getattr__(canvas_name)
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$dN/dp_T$")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name).__getattr__(est).__getattr__('dNdpT')
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$dN_{HM}/dp_T / dN_{MB}/dp_T$")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name)\
                                        .__getattr__(est)\
                                        .__getattr__('pt_hm_div_pt_mb')
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$dN_{HM}/dp_T /  dN_{MB}/dp_T \times  \left<N_{MPI}^{MB}\right> / \left<N_{MPI}^{HM}\right>$")
            for est in considered_ests:
                try:
                    c = f.MultEstimators.__getattr__(results_dir_name)\
                                        .__getattr__(est)\
                                        .__getattr__('pt_hm_div_pt_mb_scaled_nMPI')
                except AttributeError:
                    continue
                sec.add_figure(c)

            sec = latexdoc.add_section(r"$nMPI(N_{ch}) summary$")
            c = f.MultEstimators.__getattr__(results_dir_name).__getattr__('nMPI_summary')
            sec.add_figure(c)

            latexdoc.finalize_document()


description = """Create summary slides. Configurations can be made via a custom json file"""
parser_summary = subparsers.add_parser('summary', description=description)
parser_summary.add_argument('input_file', type=str, help="Path to file containing the input data")
parser_summary.add_argument('gen_name', type=str, help="Name of the generator used. Used in the title of the PDF")
# parser_summary.add_argument('-c', '--config', type=str, help="Path to json file with custom configuration.")
parser_summary.set_defaults(op=summary)


description = "Create comparison plots between two given generators"
parser_compare = subparsers.add_parser('compare', description=compare.__doc__)
parser_compare.add_argument("input_file1", type=str, help="Path to the first file to be compared")
parser_compare.add_argument("trigger1", type=str, help="Trigger of interest in first file", choices=considered_triggers)
parser_compare.add_argument("generator_name1", type=str, help="Name and tune of first generator")
parser_compare.add_argument("input_file2", type=str, help="Path to the second file to be compared")
parser_compare.add_argument("trigger2", type=str, help="Trigger of interest in second file", choices=considered_triggers)
parser_compare.add_argument("generator_name2", type=str, help="Name and tune of second generator")

parser_compare.set_defaults(op=compare)

args = parser.parse_args()
try:
    args.op(args)
except KeyboardInterrupt:
    sys.exit(1)
except Exception as e:
    if args.verbose:
        # re-raise with the full traceback
        t, v, tb = sys.exc_info()
        raise t, v, tb
    else:
        sys.exit("{0}: {1}".format(e.__class__.__name__, e))

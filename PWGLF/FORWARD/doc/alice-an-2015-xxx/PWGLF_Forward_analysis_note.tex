\documentclass[compat,11pt]{alicenote}
% \documentclass{alicenote}
% \documentclass[manyauthors]{alicenote}
% \documentclass[manyauthors,public,compat]{alicenote}
%% --- Packages ------------------------------------------------------
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{multicol}
\usepackage[ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{subfigure}
\usepackage{enumitem}
%% --- Macros etc. ---------------------------------------------------
\DeclareRobustCommand{\AlwaysText}[1]{\ifmmode\relax\text{#1}\else #1\fi}
\newcommand{\AbbrName}[1]{\AlwaysText{{\scshape #1}}}
\newcommand*\OK{\ding{51}}
\newcommand*\INEL{\AlwaysText{INEL}}
\newcommand*\NSD{\AlwaysText{NSD}}
\newcommand*\INELGT{\ifmmode\INEL>0\else$\INEL>0$\fi}
\let\INELGt\INELGT
\let\INELONE\INELGT
\newcommand\mult[1][]{\Nch\ifx|#1|\relax\else_{#1}\fi}
\newcommand*\CENT{\AlwaysText{CENT}}
\newcommand*\OCDB{\AlwaysText{OCDB}}
\newcommand*{\etaphi}{\ensuremath(\eta,\varphi)}
\newcommand{\N}[2]{{\ensuremath N_{#1#2}}}
\newcommand{\NV}[1][]{\N{\text{V}}{#1}}
\newcommand{\NnotV}{\N{\not{\text{V}}}}
\newcommand*{\NT}{\N{\text{T}}{}}
\renewcommand{\NA}{\N{\text{A}}{}}
\newcommand*{\Ngood}{{\ensuremath N_{\text{good}}}}
\newcommand*\SecMap{\ensuremath S_{\subMC,\subIPz,r}\etaphi}
\newcommand*\EmpCor[1][]{\ensuremath E\ifx|#1|\relax\else_{#1}\fi(\eta)}
\newcommand*\ESD{\AlwaysText{ESD}}
\newcommand{\AOD}{\AlwaysText{AOD}}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\DeltaMip}{\ensuremath\Delta_{\text{mip}}}
\newcommand{\minitab}[2][l]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
% \newcommand{\dndetadphi}[1][]{{\ensuremath% 
%     \ifx|#1|\else\left.\fi%
%       \frac{\mathrm{d}^2\Nch{}}{\mathrm{d}\eta\mathrm{d}\varphi}
%     \ifx|#1|\else\right|_{#1}\fi%
% }}
\newcommand{\dndetadphi}[1][]{{\ensuremath% 
    \ifx|#1|\else\left.\fi% 
      \Nch\etaphi%
      \ifx|#1|\else\right|_{#1}\fi}}
\newcommand\Ntotal{{\ensuremath N_{\text{total}}}}
\newcommand\Nempty{{\ensuremath N_{\text{empty}}}}
\newcommand\Nhit{{\ensuremath N_{\text{hit}}\etaphi_{\in R}}}
\newcommand{\landau}[1]{{\ensuremath% 
    \text{landau}\left(#1\right)}}
\newcommand{\dndphi}[1][]{{\ensuremath% 
    \ifx|#1|\else\left.\fi%
    \frac{1}{N}\frac{\mathrm{d}\Nch{}}{\mathrm{d}\varphi}%
    \ifx|#1|\else\right|_{#1}\fi%
}}
\newcommand\FIXME[1]{\marginpar{\raggedright\textbf{FIXME:} #1}}
\newcommand\headColor{\rowcolor{alicered!25!white}}
\newcommand\altRowColor{\rowcolor{aliceyellow!25!white}}

% Azimuthal acceptance
\newcommand{\Corners}{\ensuremath A^{\varphi}_{t}} 
% Acceptance due to dead strips
\newcommand{\DeadCh}{\ensuremath A^{\text{`bad'}}_{\subIPz}\etaphi} 
\newcommand{\phiAcc}{\ensuremath a_i^{\varphi}(\eta)}
\newcommand{\etaCov}{\ensuremath a_i^{\eta}(\eta)}
\newcommand{\PhiAcc}{\ensuremath a^{\varphi}(\eta)}
\newcommand{\indndeta}[1][]{{%
  \ifmmode%
    \left.\ndndeta\right|_{\text{inclusive#1}}%
  \else%
    \ndndeta$|_{\text{inclusive#1}}$%
  \fi}}
%% Figures
\newcommand\figinput[2][\textwidth]{% 
  \includegraphics[keepaspectratio,width=#1]{\jobname-#2}}
%% Tight lists
\setlist[itemize]{noitemsep,nolistsep}
\setlist[description]{noitemsep,nolistsep}
%% --- Front matter --------------------------------------------------
\title{Systematic Study of \ndndeta{} over the Widest Possible $\eta$
  Range}
\institute{1}{Niels Bohr Institute}
\annotation{*}{\protect\texttt{cholm@nbi.dk}}
\author[C.H.~Christensen \emph{et al}]{% 
  C.H.~Christensen\inst[*]{} \and 
  M.~Chojnacki\inst{1}}
\notenumber{XXXX-YY}
\date{\today}
%% === The Document ==================================================
\begin{document}

%% === The Front matter ==============================================
\maketitle{}
\renewcommand*{\thefootnote}{\arabic{footnote}}
\begin{abstract}
  \noindent
  This note details the analysis for \ndndeta{} over the widest
  possible $\eta$ range possible with \ALICE{} (and \LHC{} for that
  matter).  The analysis uses tracklets from the \SPD{} and signals
  from the \FMD{}.  All possible collision systems and energies are
  analysed.  For \ppCol{} \ndndeta{} is determined for the three
  trigger classes \INEL{}, \INELGt{}, and \NSD{}.  For \PbPbCol{},
  \pPbCol{}, and \PbpCol{} \ndndeta{} is determined in centrality
  bins. Secondary particles produced in surrounding material and
  decays are removed from the \FMD{} signal using an \emph{empirical}
  correction based on results
  from \cite{Abbas:2013bpa}. \\

  \noindent 
  The focus in this note is on the results from \PbPbCol{} at
  $\usNN{PbPb}{2760}$ over all centrality bins.  Work--in--progress
  results for other systems are also shown here, but they are not
  finalised.  Separate follow--up notes will handle those systems. \\

  \noindent
  This notes details the forward (\FMD{}) part of the analysis only.
  A separate note on the \SPD{} tracklet analysis exists elsewhere
  \cite{spdnote}.  The content of this note is in many places the same
  as in an older analysis note \cite{oldnote}, but is otherwise
  independent and can be read on its own.\\

  \noindent
  {\small TWiki page: \url{http://cern.ch/go/fm8C}}
\end{abstract}

\cleardoublepage
\tableofcontents 

\cleardoublepage

%% === The Introduction ==============================================
\section{Introduction}

This note describes the steps performed in the analysis of the
charged particle multiplicity in the forward pseudo--rapidity regions
with the \FMD{} detector \cite{FWD:2004mz,cholm:2009}. 

The \FMD{} is organised in 3 \emph{sub--detectors} \FMD{1}, \FMD{2},
and \FMD{3}, each consisting of 1 (\FMD{1}) or 2 (\FMD{2} and~3)
\emph{rings}.  The rings fall into two types: \emph{Inner} or
\emph{outer} rings.  Each ring is in turn azimuthally divided into
\emph{sectors}, and each sector is radially divided into
\emph{strips}.  The number of sectors, strips, as well as the nominal
$\eta$ coverage for each ring are given in
\tablename~\ref{tab:fmd:overview}.

\begin{table}[htbp]
  \begin{center}
    \caption{Physical dimensions of Si segments and strips.}
    \label{tab:fmd:overview}
    \vglue0.2cm
    \begin{tabular}{|c|cc|crcl|rcl|}
      \hline
      \headColor%
      \textbf{Sub--detector/} &
      \textbf{Azimuthal}&
      \textbf{Radial} &
      $z$ &
      \multicolumn{3}{c|}{\textbf{$r$}} &
      \multicolumn{3}{c|}{\textbf{$\eta$}} \\ 
      \rowcolor{alicered!25!white}
      \textbf{Ring}&  
      \textbf{sectors} &
      \textbf{strips} & 
      \textbf{[cm]} &
      \multicolumn{3}{c|}{\textbf{range [cm]}} &
      \multicolumn{3}{c|}{\textbf{coverage}} \\
      \hline
      FMD1i & 20& 512& 320  &  4.2&--&17.2& 3.68&--&5.03\\
      \altRowColor{}%
      FMD2i & 20& 512&  83.4&  4.2&--&17.2& 2.28&--&3.68\\
      FMD2o & 40& 256&  75.2& 15.4&--&28.4& 1.70&--&2.29\\
      \altRowColor{}%
      FMD3i & 20& 512& -75.2&  4.2&--&17.2&-2.29&--&-1.70\\
      FMD3o & 40& 256& -83.4& 15.4&--&28.4&-3.40&--&-2.01\\
      \hline
    \end{tabular}
  \end{center}
\end{table}

The \FMD{} \ESD{} object contains the scaled energy deposited
$\Delta_t\equiv\Delta /\DeltaMip$ for each of the 51,200 strips.  This
is determined in the reconstruction pass.  The scaling to $\DeltaMip$
is done using calibration factors extracted in designated pulser runs.
In these runs, the front--end electronics is pulsed with an increasing
known pulse size, and the conversion factor from ADC counts to
$\DeltaMip$ is determined \cite{cholm:2009}.

The \SPD{} is used for determination of the position of the primary
interaction point.

The analysis is performed as a two--step process.  
\begin{enumerate}
\item The Event--Summary--Data (\ESD{}) is processed event--by--event.
  On each event, the data is passed through a number of algorithms,
  and $\dndetadphi$ for each event is output to an
  Analysis--Object--Data (\AOD{}) tree (see \secref{sec:gen_aod}).
\item The \AOD{} data is read in and the sub--sample of the data under
  investigation is selected. For \ppCol{} we select of for example
  \INEL{}, \INELONE{}, and \NSD{}\footnote{Recently, capability to
    select on other estimators relevant for high--multiplicity studies
    have been implemented.}. For \PbPbCol{}, \pPbCol{}, and \PbpCol{}
  we select on centrality estimators.  The $\dndetadphi$ histogram
  read for the selected events is used to build up $\dndeta$ (see
  \secref{sec:ana_aod}).
\end{enumerate}
The details of each step above will be expanded upon in the
following. 

In Appendix~\ref{app:nomen} is an overview of the nomenclature used in
this document.

\section{Generating $\dndetadphi[i]$ event--by--event}
\label{sec:gen_aod}

When reading in the \ESD{}s and generating the $\dndetadphi$
event--by--event the following steps are taken (in order) for each
event $i$ and FMD ring $r$.
\begin{description}
\item[Event inspection] The global properties of the event is
  determined, including the trigger type and primary interaction
  point\footnote{`Vertex' and `primary interaction point' will be used
    interchangeably in the text, since there is no ambiguity with
    particle production vertex in this analysis.} $z$ coordinate (see
  \secref{sec:sub:event_inspection}).
\item[\ESD{} fix-up] Addition of missing noise component, and filtering
  of `bad' strips (see \secref{sec:sub:fixer}).
\item[Sharing filter] The \ESD{} object is read in and corrected for
  sharing.  The result is a new \ESD{} object (see
  \secref{sec:sub:sharing_filter}).
\item[Density calculator] The sharing corrected\footnote{Optionally,
    the sharing filter can be turned off, in which case the density
    calculator will receive the output of the \ESD{} fixer.} \ESD{}
  object is then inspected and an inclusive\footnote{By `inclusive' we
    mean primary \emph{and} secondary particles.}, per--ring number of
  charged particles $\dndetadphi[incl,r,\subIPz{},i]$ is calculated.
  The output of this step are 5 $\etaphi$ histograms --- one per
  \FMD{} ring.  This calculation depends in general upon the
  interaction vertex position along the $z$ axis $\IPz{}$ (see
  \secref{sec:sub:density_calculator}).
\item[Corrections] The 5 $\dndetadphi[incl,r,\subIPz{},i]$ histograms
  are corrected for secondary production and acceptance.  The
  correction for the secondary particle production is highly dependent
  on the vertex $z$ coordinate.  The result is a per--ring, number of
  charged primary particles $\dndetadphi[r,\subIPz{},i]$ (see
  \secref{sec:sub:corrector}).  Note, that this step is omitted when
  the correction for secondaries is done using the empirical
  correction.   In that case, the output of the density calculator is
  passed straight to the next step. 
\item[Histogram collector] Finally, the 5 $\dndetadphi[r,\subIPz{},i]$
  (or $\dndetadphi[incl,r,\subIPz{},i]$ if the previous step was
  omitted) histograms are summed into a single
  $\dndetadphi[\subIPz{},i]$ histogram, taking care of the overlaps
  between the detector rings.  In principle, this histogram is
  independent of the vertex, except that the pseudo--rapidity range,
  and possible holes in that range, depends on $\IPz{}$ --- or rather
  the bin in which the $\IPz{}$ falls (see
  \secref{sec:sub:hist_collector}).
\end{description}

Each of these steps will be detailed in the following. 

\subsection{Event inspection}
\label{sec:sub:event_inspection}

\paragraph{Trigger} 
The first thing to do, is to inspect the event for triggers.  A number
of trigger bits, like \INEL{} (Minimum Bias for Pb+Pb), \INELONE{},
\NSD{}, and so on is then propagated to the \AOD{} output.

\paragraph{Pile--up} 
The event is checked for pile-up using up three different methods
\begin{itemize}
\item \SPD{} pile--up flag from multiple interaction points
\item Track pile--up flag from multiple interaction points
\item Out--of--bunch pile--up flag from the beam parameters 
\end{itemize}
The pile--up status is propagated to the \AOD{} output.  

\paragraph{\SPD{} outlier} 
The number of clusters in the \SPD{} is compared to the number of
tracklets from the \SPD{}, and events with too many clusters compared
to the number of tracklets is flagged in the \AOD{} as an outlier
event.

\paragraph{Interaction point $z$ coordinate ($\IPz$)} 
Depending on the settings, the interaction point coordinates is
queried from the input \ESD{} and propagated to the \AOD{}.  In
general, and \SPD{} primary vertex is required, but this can be
changed if needed. 

Just after the sharing filter (see \secref{sec:sub:sharing_filter})
but before any further processing, the interaction point information
is queried.  If there is no information, or if the interaction point
$z$ coordinate ($\IPz$) is outside the pre--defined range, then no
further processing of that event takes place.

\subsubsection{Satellite Vertices}
\label{sec:sub:sub:dispvtx}

The analysis can be set up to run on the `displaced vertices' that
occur during \LHC{} 2010 \PbPbCol{} running. Details on the displaced
vertices, and their selection can be found in the \VZERO{} analysis note
\cite{maxime} (see also \secref{sec:sub:empirical}).

\subsection{\ESD{} fix-up}
\label{sec:sub:fixer} 

The \FMD{} strip signals in the \ESD{} are not aligned at the real zero,
due to a bug in the reconstruction code.  In the reconstruction pass
only a $1\times\sigma$ ($\sigma$ is the noise in a given strip) was
added, but the electronics had suppressed $4\times\sigma$.  To align
at the proper zero, we therefor add $3\times\sigma$ scaled by the gain
factor $\DeltaMip$.

For some of the earlier runs, the off--line shuttle\footnote{The
  software that processes only conditions and writes these to the
  Off--line Conditions DataBase (OCDB).}\ did not properly flag certain
strips as `bad'.  We therefore flag additional problematic strips in
this pass as `bad'.  `Bad' in this context means high noise or low
gain, or a noise--to--gain factor larger than some cut-off (typically
0.4). 

The result of this step is a modified \ESD{} object which is passed on
in to the next step in the chain. 


\subsection{Sharing filter}
\label{sec:sub:sharing_filter}

A particle originating from the vertex can, because of its incident
angle on the \FMD{} sensors traverse more than one strip (see
\figref{fig:share_fraction}).  This means that the energy loss of the
particle is distributed over 1 or more strips.  The signal in each
strip should therefore possibly be merged with its neighbouring strip
signals to properly reconstruct the energy loss of a single particle.

\begin{figure}[htbp]
  \centering
  \figinput[3cm]{share_fraction}
  \caption{A particle traversing 2 strips and depositing energy in
    each strip. }
  \label{fig:share_fraction}
\end{figure}

\iffalse
%% 
%% Since we no longer distinguish between high or low flux events,
%% this paragraph is largely irrelevant and therefor removed
%%
The effect is most pronounced in low--flux\footnote{Events with a low
  hit density.} events, like proton--proton collisions or peripheral
Pb--Pb collisions, while in high--flux events the hit density is so
high that most likely each and every strip will be hit and the effect
cancels out on average.
\fi

Since the particles travel more or less in straight lines toward the
\FMD{} sensors, the sharing effect is predominantly in the $r$ or
\emph{strip} direction.  Only neighbouring strips in a given sector are
therefore investigated for this effect.  

\begin{figure}[htbp]
  \centering
  \figinput[.8\linewidth]{sharing}
  \caption{The effect of the sharing filter.  The light distributions
    are from the reconstruction, while the darker distributions are
    after the algorithm has been applied.  The yellow band indicates
    the lower excluded region, while the cyan band illustrates the
    spread of the high cut. }
  \label{fig:sharing:effect}
\end{figure}


Algorithm~\ref{algo:sharing}\footnote{The algorithm is shown here
  almost as it is coded.  As it stands here, it could easily be
  simplified.  However, in the code (\texttt{AliFMDSharingFilter})
  there are side--effects and settings which will influence the flow.}
is applied to the signals in a given sector.

\begin{algorithm}[htpb]
  \belowpdfbookmark{Algorithm 1}{algo:sharing}
  \SetKwData{used}{u}
  \SetKwData{Output}{o${}_t$}
  \SetKwData{Input}{i}
  \SetKwData{Nstr}{N}
  \SetKwData{Signal}{c}
  \SetKwData{Sum}{s}
  \SetKwData{Eta}{$\eta$}
  \SetKwData{Low}{l}
  \SetKwData{High}{h}
  \SetKwData{Next}{n} 
  \SetKwData{Tmp}{t} 
  \SetKw{continue}{continue}
  \SetCommentSty{textit}
  \SetKwComment{Cm}{}{}
  \SetKwData{assign}{\ifmmode\leftarrow\else$\leftarrow$\fi}
  %% \SetKwData{nextNextE}{next-to-next strip signal} 
  \SetKwFunction{SignalInStrip}{SignalInStrip}
  \SetKwFunction{GetLowCut}{GetLowCut}
  \SetKwFunction{GetHighCut}{GetHighCut}
  \used \assign false\Cm*{Previous strip used?}
  \Sum \assign -1\Cm*{Current sum}
  \For(\Cm*[f]{Loop over \Nstr strips}){$t$ \assign $1$ \KwTo \Nstr}{ 
    \Output\assign 0\Cm*{Default result}
    \Signal \assign \SignalInStrip($t$)\Cm*{Current strip signal}
    \uIf{$t \ne$ \Nstr}{% 
      \Next \assign \SignalInStrip($t+1$)\Cm*{Next strip signal}
    }
    \Else{% 
      \Next \assign 0\;
    }
    \lIf(\Cm*[f]{If the next is `bad'}){\Next is not valid}{
      \Next \assign 0}
    \Eta\assign $\eta$ of $t$\Cm*{Current strip $\eta$}
    %% 
    \lIf(\Cm*[f]{If `bad}){\Signal is not valid}{%
      \Output \assign invalid} 
    \If(\Cm*[f]{Null or
      invalid signal}){\Signal is not valid $\vee$ \Signal $=$ 0}{%
      
      \lIf(\Cm*[f]{If current sum is non-zero, flush it}){\Sum $>$ 0
        $\wedge$ $t\ne1$}{%
        \Output \assign \Sum        
      }
      \Sum \assign -1\Cm*{Clear flag and sum}
      \used \assign false\;
      \continue\Cm*{To next strip}
    }
    \Low \assign\GetLowCut(\Eta)\Cm*{Get low cut}
    \High \assign\GetHighCut(\Eta)\Cm*{Get high cut}
    \Tmp \assign 0\Cm*{Figure out what to take}
    \uIf(\Cm*[f]{If we already have some}){\Sum $>$ 0}{% 
      \Tmp \assign \Sum\Cm*{Then take that}
      \Sum \assign -1\Cm*{Clear flag and sum}
      \used \assign false\;
    }
    \Else(\Cm*[f]{No current sum}){% 
      \If(\Cm*[f]{Already used}){\used}{%
        \used \assign false\;
        \continue\Cm*{Move on to the next}
      }
      \lIf(\Cm*[f]{Not noise}){\Signal $>$ \Low}{\Tmp \assign \Signal}
      \If(\Cm*[f]{This and next not noise, and one is small}){%
        \Signal $>$ \Low $\wedge$ \Next $>$ \Low $\wedge$ 
        (\Signal $<$ \High $\vee$ \Next $<$ \High)}{% 
        \uIf(\Cm*[f]{Which is larger?}){\Signal $>$ \Next}{% 
          \Tmp \assign \Signal $+$ \Next\Cm*{This larger, assign here}
          \used \assign true\Cm*{Do not take this on next pass}
        }
        \Else{ 
          \Tmp \assign 0\Cm*{Next larger, assign next iteration}
          \Sum \assign \Signal $+$ \Next\;
        }
      }
    }
    \Output \assign \Tmp\Cm*{Assign output for this strip}
  }
  \caption{Sharing correction}
  \label{algo:sharing}
\end{algorithm}

Here the function \FuncSty{SignalInStrip}($t$) returns the properly
path--length corrected signal in strip $t$.   Two cuts are used in
this algorithm: 

\begin{description}
\item[\FuncSty{GetLowCut}] Signals below this cut is considered
  pedestal remnants and are never merged. 
\item[\FuncSty{GetHighCut}] Signals above this cut are considered
  isolated hits, but can be merged with a neighbouring signal below
  this cut. 
\end{description}

The exact value returned by the two functions  \FuncSty{GetLowCut} and
\FuncSty{GetHighCut} and how it those values are obtained can be
varied in the analysis (see also \secref{sec:cuts}).  

The result of this pass is a new \ESD{} object where signals that are
spread of two strips have been merged into one (see also
\figref{fig:sharing:effect}).
%% \clearpage

\subsection{Density calculator}
\label{sec:sub:density_calculator}

The density calculator loops over all the strip signals in the sharing
corrected\footnote{The sharing correction can be disabled, in which
  case the density calculator uses the input \ESD{} signals.} \ESD{}
and calculates the inclusive (primary + secondary) charged particle
density in pre--defined $\etaphi$ bins.  The output is stored in 5
$\etaphi$ binned histograms --- one for each of the sub-detectors
\FMD{1i}, 2i, 2o, 3o, and 3i.  The exact binning of the histograms
depends on settings, but default values are listed in
\tabref{tab:etaphi:binning}.

\begin{table}[h!tbp]
  \centering
  \caption{Default $\etaphi$ binning}
  \begin{tabular}[t]{|c|ccc|ccc|}
    \hline
    \headColor%
    \textbf{Sub-} & \multicolumn{3}{c|}{$\mathbf{\eta}$} & 
    \multicolumn{3}{c|}{$\mathbf{\varphi}$}\\
    \headColor%
    \textbf{detector} & \# bins & Min. & Max. & \# bins & Min. & Max. \\
    \hline
    \FMD{1i},2i,3i & 200 & -4  & 6 & 20 & 0 & $2\pi$ \\
    \altRowColor%
    \FMD{2o},3o    & 200 & -4  & 6 & 40 & 0 & $2\pi$ \\
    \hline
  \end{tabular}
  \label{tab:etaphi:binning}
\end{table}

To evaluate the charge particle multiplicity for a given strip $t$, we
evaluate the weighted energy loss fits (see \secref{sec:fits}) at the
reconstructed (possibly merged) energy loss $\Delta_t$ of the strip 
\begin{align}
  \label{eq:nt}
  n_t &= G_{N_{\text{max}}}(\Delta_t;\Delta_p,\xi,\sigma,\mathbf{a}) =
  \frac{\sum_i^{N_{max}} i\,a_i\,f_i(\Delta_t;\Delta_p,\xi,\sigma)}{
    \sum_i^{N_{max}}\,a_i\,f_i(\Delta_t;\Delta_p,\xi,\sigma)}\quad,
\end{align}
That is, the $\Nch$ weighted average of the fit to the energy loss
distributions at the given energy loss $\Delta_t$. 

The sensors of the \FMD{} are not perfect arc--segments
\cite{cholm:2009} --- the two top corners are cut off to allow the
largest possible sensor on a 6'' Si-wafer.  This means, however, that
the strips in these outer regions do not fully cover $2\pi$ in
azimuth, and there is therefore a need to correct for this limited
acceptance.

The correction is only applicable where the strip length does not
cover the full sector.  This is the case for the outer strips in both
the inner and outer type rings.  The acceptance correction is then
simply
\begin{align}
  \label{eq:acc_corr}
  \Corners{} &=
     \left\{
       \begin{array}{cl}
         1 & \text{for non-cut strips}\\
         \Delta\varphi/l_t & \\
       \end{array}\right.
     \quad
\end{align}
where $l_t$ is the strip length in radians at constant $r$, and
$\Delta\varphi$ is $2\pi$ divided by the number of sectors in the ring
(20 for inner type rings, and 40 for outer type rings). Note, that
this correction is a hardware--related correction, and does not depend
on the properties of the collision (e.g., primary vertex location).

We can then define the $\varphi$--acceptance corrected signal in a strip
$t$ as 
\begin{align}
  n'_t &= \Corners{} n_t
\end{align}

To fill the 5 per--ring, per--event, $\etaphi$, vertex-dependent
output histograms $\dndetadphi[incl,r,\subIPz,i]$ we can proceed in
one of two ways detailed in the following.

\subsubsection{Inclusive number of charged particles: Energy Fits} 
\label{sec:sub:sub:eloss_fits}

For this method, we simply sum up $n'_t$ for all strips that fall
within an $\etaphi$ bin.  
\begin{align}
  \label{eq:density1}
  \dndetadphi[incl,r,\subIPz,i] &= \sum_t^{t\in\etaphi} n'_t
\end{align}
where $t$ runs over the strips in the $\etaphi$ bin. 

This method has the advantage that it takes into account the energy
loss $\Delta_t$ of each strip.  The down--side of the the approach is
that it is sensitive to the event sample to which
$f_N(xt;\Delta_p,\xi,\sigma)$ where fitted.  For low--multiplicity
environments such as \ppCol{} the sensitivity is relatively small,
while this method implies a bias toward the minimum bias sample for
larger multiplicities. 

\subsubsection{Inclusive number of charged particles: Poisson Approach} 
\label{sec:sub:sub:poisson}

% \newcommand\muR{\ensuremath\mu_R}
\newcommand\muR{\ensuremath\mu}
Another approach to the calculation of the number of charged particles
is using Poisson statistics. This is the default choice because it is
less sensitive to the stability of the fits and the underlying data
required for the energy fits method. 

Firstly we define a strip $t$ as being `hit' if 
\begin{align*}
  t_{\text{hit}} &= \left\{ 
    \begin{array}{cl}
      1 & \Delta_t > c(\eta_t) \wedge\ n'_t > 0.9\\
      0 & 0 \leq \Delta_t \leq c(\eta_t)\vee\  0 \leq \vee n'_t \leq 0.9\\
      \text{undefined} & \text{otherwise}\\ 
    \end{array}\right.
\end{align*}
where $c(\eta_t)$ is some cut that defines a lower threshold for when
a signal is considered a `hit' (see also \secref{sec:cuts}).  For a
given set of strips $R$ we then define 
\begin{align*}
  \Nempty{} &= \sum_t^{t\in R\wedge\ t_{hit}=0}\\
  \Ntotal{} &= \sum_t^{t\in R\wedge\ t_{hit}\neq\text{undefined}}\quad,\\
\end{align*}
that is, the number of strips in $R$ with a valid signal below the
threshold and the number of strips with a valid (possibly 0) signal. 

Now, assume in the region $R$ the $\mult$ is distributed according to
a Poisson distribution with mean $\muR$.  This implies the
probability of $\mult=n$ is:
\begin{equation}
  P(n) = \frac{\muR^n e^{-\muR}}{n!} \label{eq:PoissonDef}
\end{equation}
In particular we have 
\begin{align*}
  \frac{\Nempty{}}{\Ntotal{}} &=   P(0) = e^{-\muR} \\
\intertext{and we find}
   \muR &= -\log\left(\frac{\Nempty{}}{\Ntotal{}}\right) = -\log(f)\quad,
\end{align*}
with $f=\Nempty{}/\Ntotal{}$.  That means we can calculate the mean
number of particles per $\etaphi$ bin of a larger $\etaphi$ region by
simply count the number of strips with no signal\footnote{Or rather, a
  signal below threshold.}.

The expected number of particles in a strip \emph{with a signal above
  threshold} is then given by
\begin{align}
  N_{\text{expected},R} &= \frac{\sum_{n>0}nP(n)}{\sum_{n>0}P(n)} 
  =  \frac1{1-P(0)}\sum_{n>0}n\frac{\muR^n}{n!}e^{-\muR} \nonumber\\
  \intertext{pulling out $\muR e^{-\muR}$}\nonumber
  &= \frac{e^{-\muR}}{1-e^{-\muR}}\muR\sum_{n>0}\frac{\muR^{n-1}}{(n-1)!} 
  =
  \frac{e^{-\muR}}{1-e^{-\muR}}\muR\sum_{m=0}\frac{\muR^m}{m!}\\
  \intertext{Identifying the sum $\sum_m\muR^m/m! = e^{\muR}$, we get}\nonumber
  &= \frac{e^{-\muR}}{1-e^{-\muR}}\muR e^{\muR}  = 
  \frac{\muR}{1-e^{-\muR}}\nonumber\\
  \intertext{Inserting $\muR=-\log(f)$ gives}\nonumber
  &=
  \frac{-\log(f)}{1-e^{\log(f})}
   =  \frac{-\log(f)}{1-f}
\end{align}
and the final number of particles in each of the $\etaphi$ bin of the
defined region becomes 
\begin{align}
  \label{eq:density2}
  \dndetadphi[incl,r,\subIPz,i] &= \Nhit{}\,N_{\text{expected},R} 
%% The below only applies for the case where the region is exactly the
%% size of the (eta,phi)
%% = 
%%  (\Ntotal-\Nempty)\frac{-\log\left(\frac{\Nempty{}}{\Ntotal{}}\right)}{1-\frac{\Nempty{}}{\Ntotal{}}} 
%%   = \Ntotal{}\log\left(\frac{\Nempty{}}{\Ntotal{}}\right)
\end{align}
where $\Nhit{}$ is the number of strips in the given $\etaphi$ bin
\emph{with} a signal above the defined threshold.

The size of the regions used can be varied in the analysis.  The
default is $\unit[32]{strips}\times\unit[4]{sectors}$ (see also
\tabref{tab:fmd:overview}).  The exact definition of the threshold can
likewise be varied (see also \secref{sec:cuts}). 

\begin{figure}[htbp]
  \centering
  \figinput[.8\linewidth]{corr_method}
  \caption{Correlation of the two methods to estimate
    $\dndetadphi[incl,r,\subIPz,i]$.  The spread for all sub--detectors is
    less than 1\%.}
  \label{fig:density:corr}
\end{figure}


The Poisson method and the energy fits method have been compared in
\cite{hhd:2009} where it is found that the two methods are in good
agreement. The residual difference between the methods contributes to
the systematic error (see also \figref{fig:density:corr}).

\subsubsection{Azimuthal ($\varphi$) Acceptance} 

For a given $\eta$ bin, the calculation
$\dndetadphi[incl,r,\subIPz,i]$ also counts the number of strips with
$t_{hit}\neq\text{undefined}$ and the total number of strips, and then
forms the ratio
\begin{align}
  \label{eq:overflow}
  \phiAcc &= \frac{\sum_t^{t\in\eta \wedge
      t\neq\text{undefined}}}{\sum_t^{t\in\eta}} \quad,
\end{align}
which is the per--event, per $\eta$ range azimuthal acceptance.  This
number is stored in the corresponding overflow bin of the 5 output
$\etaphi$ histograms, and can late be used to correct for the
$\varphi$ acceptance.

\subsection{Corrections}
\label{sec:sub:corrector}

\begin{center}
  \begin{tabular}{|p{.9\linewidth}|}
    \arrayrulecolor{alicepurple}
    \hline
    \cellcolor{alicered!20}\\
    \cellcolor{alicered!20}
    The corrections described in this section are by default turned off.
    We outline them here mainly for historical and reference
    purposes. That means that 
    \begin{equation}
      \dndetadphi[r,\subIPz,i] = \dndetadphi[incl,r,\subIPz,i]
    \end{equation}\\
    \hline
  \end{tabular}
\end{center}

The corrections code receives the five vertex dependent,
per--ring histograms of the inclusive charged particle density
$\dndetadphi[incl,r,\subIPz,i]$ from the density calculator and applies
up to two corrections.   

\subsubsection{Secondary correction}
\label{sec:sub:sub:secmap}
%%
%%                hHits_FMD<d><r>_vtx<v> 
%% hCorrection = -----------------------
%%                hPrimary_FMD_<r>_vtx<v>
%%
%% where 
%% - hPrimary_FMD_<r>_vtx<vtx> is 2D of eta,phi for all primary ch
%%   particles
%% - hHits_FMD<d><r>_vtx<v>  is 2D of eta,phi for all track-refs that
%%   hit the FMD - The 2D version of hMCHits_nocuts_FMD<d><r>_vtx<v>
%%   used below. 
This is a 2 dimensional histogram generated from simulations, as the
ratio of primary particles to the total number of particles that fall
within an $\etaphi$ bin for a given vertex bin

\begin{align}
  \label{eq:secondary}
  \SecMap{} &=
  \frac{\sum_i^{\NV[,\subIPz]}\mult[,\text{primary},i]\etaphi}{
    \sum_i^{\NV[,\subIPz]}\mult[,\text{\FMD{}},i]\etaphi}\quad,
\end{align}
where 

\begin{tabular}[T]{p{.18\linewidth}p{.78\linewidth}}
  $\NV[,\subIPz]$ & is the number of events with a valid trigger
                    and a vertex in bin $\IPz$.\\ 
  $\dndetadphi[\FMD{},i]$ & is the total number of charged
                            particles that hit the \FMD{} in event $i$
                            in the specified $\etaphi$ bin.  This
                            number is counted from the simulation, and
                            not  after the
                            reconstruction\footnote{Technically, we 
                            are counting `track references' within the
                            $\etaphi$ bin for a given
                            sub-detector.}.\\  
  $\dndetadphi[\text{primary},i]$ & is number of primary charged
                                    particles in event $i$ within the
                                    specified $\etaphi$ bin.  This is
                                    counted \emph{at the time of the
                                    collision} as defined in the
                                    simulation code.  That is, it is
                                    the number of primaries within the
                                    $\etaphi$ bin at the collision
                                    point --- not at the \FMD{}. 
\end{tabular}
\iffalse
\begin{description}
\item[] $\NV[,\subIPz]$ is the number of events with a valid trigger
  and a vertex in bin $\IPz$.
\item[] $\dndetadphi[\FMD{},i]$ is the total number of charged
  particles that hit the \FMD{} in event $i$ in the specified
  $\etaphi$ bin.  This number is counted from the simulation, and not
  after the reconstruction\footnote{Technically, we are counting
    `track references' within the $\etaphi$ bin for a given
    sub-detector.}.
\item[] $\dndetadphi[\text{primary},i]$ is number of primary charged
  particles in event $i$ within the specified $\etaphi$ bin.  This is
  counted \emph{at the time of the collision} as defined in the
  simulation code.  That is, it is the number of primaries within the
  $\etaphi$ bin at the collision point --- not at the \FMD{}.
\end{description}
\fi

$\SecMap$ varies from $\approx 1.5$ for the most forward bins to
$\approx 3$ for the more central bins. Figure \ref{secondaries} shows
the $\dndeta$ of secondaries from various sources assessed with MC
simulations to give an idea of the magnitude of the effects of
secondaries.

\begin{figure}[]
  \centering
  \figinput[.9\textwidth]{secondary_origin}
  \caption{$\dndeta$ for secondaries and primaries in the \FMD{} and
    \SPD{}, with origin of secondaries shown.}
  \label{secondaries}
\end{figure} 

\begin{figure}[]
  \centering
  \figinput[.8\textwidth]{secmap_pp_aa_one}
  \caption{Top shows projection of $\SecMap$ onto the $\eta$ axis for
    one interaction point bin ($\unit[0]{cm}<\IPz{}<\unit[2]{cm}$).
    The different colours correspond the 5 \FMD{} rings.  The
    different symbols correspond to different collisions systems
    simulated in \texttt{LHC14i2}.  The bottom shows the ratio
    $\SecMap$ for each collision system to the average $\SecMap$ over
    all collision systems. All systems fall with--in 5\%, except
    \PbpCol{} and \PbPbCol{} in \FMD{1} which deviates with up to
    10\%. }
  \label{fig:secmap:all}
\end{figure} 
 
The systematics of the secondary correction was evaluated through a
comprehensive simulation production
(\href{https://alimonitor.cern.ch/job_details.jsp?jt_field1=LHC14i2}{\texttt{LHC14i2}})
where all collision systems where simulated with the same underlying
geometric description. An example of that study is shown in
\figref{fig:secmap:all}.  It is seen, that the secondary map is
independent of the particle multiplicity, as one would expect from how
the track propagation code (\GEANT{3}) works: Each track is propagated
independent of other particles --- \textit{i.e.}, one will get the
same value of $\SecMap$ from $N$ events with $n$ particles as one
would from a single event with $N\times n$ particles, or $N\times n$
events with a single particle.


However, there are some other small differences between between the
systems as can be seen from \figref{fig:secmap:all}.  Most notable is
the discrepancy between \PbpCol{} and \PbPbCol{} and all other system
in \FMD{1}. 
\FIXME{Marek, we should somehow either refer to another section, or
  add your studies here.} 

%For pp, different event
%generators were used and found to give compatible results within
%3--5\%.   
For \ppCol{}, at least some millions of events must be accumulated to
reach satisfactory statistics.  For \PbPbCol{} where the general hit
density is larger, reasonable statistics can be achieved with less
simulated data. \pPbCol{}/\PbpCol{} sits somewhere in between. 

\subsubsection{Acceptance due to dead channels}

Some of the strips in the \FMD{} have been marked up as \emph{dead},
meaning that they are not used in the reconstruction or analysis.
This leaves holes in the acceptance of each defined $\etaphi$ which
need to be corrected for.

The map of strips marked as `bad' is stored in the off-line conditions
database (\OCDB{}), and based on this information and the geometric
description we can built up per--vertex bin $\IPz$ acceptance maps
\begin{align}
  \label{eq:dead_channels} 
  \DeadCh{} &= 
  \frac{\sum_t^{t\in\etaphi}\left\{\begin{array}{cl}
        1 & \text{if `bad'}\\
        0 & \text{otherwise}
      \end{array}\right.}{\sum_t^{t\in\etaphi} 1}\quad,
\end{align}
where $t$ runs over the strips in the $\etaphi$ bin.  This correction
is obviously $\IPz$ dependent since the $\etaphi$ bin to which a strip $t$
corresponds to depends on its position relative to the primary
interaction point. 

The 5 output vertex dependent, per--ring histograms of the primary
charged particle density is then given by
\begin{align}
  \dndetadphi[r,\subIPz,i] &=
  \SecMap{} \frac{1}{\DeadCh{}}\dndetadphi[incl,r,\subIPz,i]
\end{align}

\subsection{Histogram collector}
\label{sec:sub:hist_collector}

The histogram collector collects the information from the 5 vertex
dependent, per--ring histograms of the primary charged particle
density $\dndetadphi[r,\subIPz,i]$ into a single vertex dependent
histogram of the charged particle density $\dndetadphi[\subIPz,i]$.

In case the secondary map correction was turned off, as in the case
when the empirical correction is applied, the histogram collector
receives the 5 vertex dependent, per--ring histograms of the
\emph{inclusive} charged particle density
$\dndetadphi[incl,r,\subIPz,i]$ and collect these into a single vertex
dependent histogram of the \emph{inclusive} charged particle density
$\dndetadphi[incl,\subIPz,i]$.  In either case, the same algorithm is
applied, and one can substitute the inclusive histograms for primary
histogram in the below description. 

To do this, it first calculates, for each vertex bin, the $\eta$ bin
range to use for each ring.  It investigates the secondary correction
maps $\SecMap{}$ to find the edges of each map.  The edges are given
by the $\eta$ range where $\SecMap{}$ is larger than some
threshold\footnote{Typically $t_s\approx 0.1$.}  $t_s$. The code
applies safety margin of a number of bins,
$N_{cut}$\footnote{Typically $N_{cut}=1$.}, to ensure that the data
selected does not have too large corrections associated with it.

It then loops over the bins in the defined $\eta$ range and sums the
contributions from each of the 5 histograms.  In the $\eta$ ranges
where two rings overlap, the collector calculates the average and adds
the errors in quadrature\footnote{While not explicitly checked, it was
  found that the histograms agrees within error bars in the
  overlapping region}.

The output, vertex dependent, histogram of the primary
charged particle density is then given by
\begin{align}
  \label{eq:superhist}
  \dndetadphi[\subIPz,i] &=
  \frac{1}{N_{r\in\etaphi}}\sum_{r}^{r\in\etaphi}  
  \dndetadphi[r,\subIPz,i]\\
  \delta\left[\dndetadphi[\subIPz,i]\right] &=
  \frac{1}{N_{r\in\etaphi}}\sqrt{\sum_{r}^{r\in\etaphi}   
    \delta\left[\dndetadphi[r,\subIPz,i]\right]^2}
  \quad,
\end{align}
where $N_{r\in\etaphi}$ is the number of overlapping histograms
in the given $\etaphi$ bin. 

If the secondary map correction was turned of, this becomes 
\begin{align}
  \label{eq:superhist:2}
  \dndetadphi[incl,\subIPz,i] &=
  \frac{1}{N_{r\in\etaphi}}\sum_{r}^{r\in\etaphi}  
  \dndetadphi[incl,r,\subIPz,i]\\
  \delta\left[\dndetadphi[incl,\subIPz,i]\right] &=
  \frac{1}{N_{r\in\etaphi}}\sqrt{\sum_{r}^{r\in\etaphi}   
    \delta\left[\dndetadphi[incl,r,\subIPz,i]\right]^2}
\end{align}

The histogram collector stores the found $\eta$ ranges in the
underflow bin of the histogram produced.  The content of the underflow
bins are 
\begin{align}
  \label{eq:underflow}
  \etaCov &= 
  \frac{1}{N_{r\in(\eta)}}
  \sum_{r}^{r\in(\eta)} \left\{\begin{array}{cl} 
      0 & \eta \text{\ bin not selected}\\ 
      1 & \eta \text{\ bin selected}
      \end{array}\right.\quad,
\end{align}
where $N_{r\in(\eta)}$ is the number of overlapping histograms in the
given $\eta$ bin.  The subscript $i$ indicates that the content
depends on the current interaction point of event $i$.

\begin{figure}[]
  \centering
  \figinput[.9\textwidth]{steps}
  \caption{Step--by--step evolution of $\dndeta$ in the analysis.
    Note for this particular analysis, the secondary correction
    $\SecMap{}$ was turned off (see \secref{sec:sub:sub:secmap}). The
    figure should be read from the top-left, towards the right,
    continuing on the bottom left, and finally ending up in the lower
    right. Dark blue markers are for \FMD{3i}, light blue is
    \FMD{3o}, light green \FMD{2o}, dark green \FMD{2i}, and red
    \FMD{1i}.}
  \label{fig:steps}
\end{figure} 

All the steps involved are summarised in \figref{fig:steps}. 

\subsection{The final \AOD{} output} 

The final \FMD{} \AOD{} is stored on a separate branch\footnote{The
  branch name is \texttt{Forward} for normal data, and
  \texttt{ForwardMC} for simulated data. Both branches store a single
  \texttt{AliAODForwardMult} object per event.} and contains 

\begin{tabular}[T]{p{.2\linewidth}p{.76\linewidth}}
  $\dndetadphi[\subIPz,i]$ & A 2--dimensional histogram of the
                             exclusive number of charged primary
                             particles per $\etaphi$ bin
                             \eqref{eq:superhist}, \emph{or}\\ 
  $\dndetadphi[incl,\subIPz,i]$ & A 2--dimensional histogram of the
                                  inclusive number of charged primary
                                  and secondary particles per
                                  $\etaphi$ bin \eqref{eq:superhist:2}
                                  in case the secondary map correction
                                  was turned off.\\   
  $\phiAcc{}$ & A 1--dimensional histogram of the $\varphi$ acceptance
                per $\eta$ bin \eqref{eq:overflow}. \\
  $\IPz$ & The $z$ coordinate of the interaction point used in the
           above steps.\\
  Trigger bits & A bit field of seen triggers and conditions
                 (pile--up, \SPD{} outlier, etc.) during the above steps.\\ 
\end{tabular}


%% === AOD analysis ==================================================
\clearpage
\section{Building the final $\dndeta$}
\label{sec:ana_aod}

\subsection{Event selection}

To build the final $\dndeta$ for a given event selection $X$ we loop
over the events stored in the \AOD{} and extract the per--event,
vertex dependent, exclusive or inclusive number of charged particles
per $\etaphi$ bin.   Generally, the event selection consists of 

\begin{enumerate}
\item Selecting events with a primary interaction that has a $z$
  coordinate $\IPz$ within some specified range --- typically
  $|\IPz|\le\unit[10]{cm}$. 
\item Rejecting events that have been flagged as containing pile--up.
  Typically, the \SPD{} tracklet pile--up flag is used. 
\item Rejecting events that have been flagged as an \SPD{} outlier
  event. 
\item Selecting events that have a given trigger type.
  \begin{itemize}
  \item A trigger type $X$ can be simple triggers like \texttt{MBOR},
    \texttt{MBOR} and at least one tracklet in the \SPD{} within
    $|\eta|<1$ (a.k.a.~\INELGT{}), or \texttt{V0AND}. 
  \item Alternatively, the trigger $X$ can depend on some event
    characteristic e.g., centrality or reference multiplicity. In that
    case, we select on the quantity and perform the analysis in bins
    of that quantity.
  \end{itemize}
\end{enumerate}

All standard centrality estimators are supported.  Furthermore, the
reference multiplicity\footnote{The number of unique tracks and
  tracklets within $|\eta|<0.8$.} is supported, as well as the special
\ppCol{} centrality estimators developed for the RunII
High--Multiplicity Task--Force.

\paragraph{\ppCol{} event classes and trigger efficiencies} 

When determining $\dndeta$ for physical event classes, such as
the full in--elastic cross--section, or the non--single--diffractive
events, in \ppCol{} we choose the underlying hardware and replayed
software trigger that gives the highest efficiency for that event
class.  \tabref{tab:dndeta:ppclasses} summarises the interesting
physical event classes in \ppCol{}, together with the underlying
trigger and its corresponding efficiency for each of the studied
collision energies.  Note, that the event class \INELGT{} is a pure
experimental event class, and as such the trigger efficiency is by
definition unity. 

\begin{table}[hbtp]
  \centering
  \caption{The \ppCol{} event classes and their corresponding
    underlying trigger and the efficiency \cite{pwgud:2015}.}
  \begin{tabular}{|cc|cccc|}
    \hline 
    \headColor%
    \textbf{Event} 
    & \textbf{Underlying} 
    & \multicolumn{4}{c|}{\textbf{Trigger efficiency}}\\
    \headColor%
    \textbf{class} 
    & \textbf{trigger} 
    & \multicolumn{4}{c|}{$\mathbf{\sqrt{s}}$}\\
    \headColor%
    &
    & \GeV[900]{}
    & \TeV[2.76]{} 
    & \TeV[7]{} 
    & \TeV[8]{}\\
    \hline
    \INEL{} & \texttt{MBOR} 
    & $0.91^{+0.03}_{-0.01}$ 
    & $0.88^{+0.06}_{-0.035}$ 
    & $0.85^{+0.06}_{-0.03}$ 
    & $0.85^{+0.06}_{-0.03}$\\
    \altRowColor{}%
    \INELGT{} & \texttt{MBOR} \& $N_{\text{tracklet},|\eta|<1}\ge1$ 
    & \multicolumn{4}{c|}{1} \\
    \NSD{} & \texttt{V0AND} 
    & $0.94\pm0.02$ 
    & $0.93\pm0.03$ 
    & $0.93\pm0.02$ 
    & $0.93\pm0.02$ \\
    \hline
  \end{tabular}
  \label{tab:dndeta:ppclasses}
\end{table}


\subsection{Summing $\dndeta$ and normalisation} 

To build the final $\dndeta$ distribution it is enough to sum
\eqref{eq:superhist} (\eqref{eq:superhist:2} if the secondary map
correction was turned off) and \eqref{eq:overflow} over all accepted
events, $\NA$, and correct for the acceptance
$\PhiAcc{}\,$\footnote{Since $\phiAcc$ is 1 or slightly less, we have
  that $\PhiAcc$ is roughly equal to (but not bigger than) $\NA$.}
\begin{align}
  \dndetadphi &= \sum_i^{\NA}\dndetadphi[i,\subIPz]\\ 
  \PhiAcc &= \sum_i^{\NA}\phiAcc\\
\intertext{and integrating over $\varphi$ gives}
  \ndndeta &=
  \frac{\NA}{\N{X}{}} \frac1{\Delta\eta} \int_0^{2\pi} \text{d}\varphi
  \frac{\dndetadphi}{\PhiAcc}\quad,\label{eq:eventnormdndeta}
\end{align}
where $\NA/\N{X}{}$ is the trigger normalisation.  The trigger
normalisation is given by 
\begin{align}
  \N{X}{} &= \frac{1}{\epsilon_X}\left[\NA +
    \alpha(\NnotV -
    \beta)\right]  \label{eq:fulleventnorm}\\
  & = \frac{1}{\epsilon_X}\left[\NA + \frac{\NA}{\NV}(\NT-\NV{} -
    \beta)\right]\nonumber \\
  & =\frac{1}{\epsilon_X}\NA\left[1+\frac{1}{\epsilon_V}-1-
    \frac{\beta}{\NV}\right]\nonumber\\
  & = \frac{1}{\epsilon_X}\frac{1}{\epsilon_V}\NA
  \left(1-\frac{\beta}{\NT{}}\right)\nonumber
\end{align}
where
\begin{description}
\item[$\epsilon_X$]  is the trigger efficiency for type
  $X\in\{\INEL,\INELONE,\NSD\}$ for \ppCol{} data and $\text{CENT}$
  for \PbPbCol{} and \pPbCol{}/\PbpCol{} data
\item[$\epsilon_V=\frac{\NV{}}{\NT{}}$] is the primary vertex
  efficiency evaluated over the data.
\item[$\NA$] is the number of events with a trigger \emph{and} a valid
  vertex in the selected range
\item[$\NV{}$] is the number of events with a trigger \emph{and} a valid
  vertex. 
\item[$\NT$] is the number of events with a trigger.
\item[$\NnotV{}=\NT-\NV{}$] is the number of events with a trigger
  \emph{but no} valid vertex
\item[$\alpha=\frac{\NA}{\NV}$] is the fraction of accepted events of
  the total number of events with a trigger and valid vertex.  
\item[$\beta=\N{a}{}+\N{c}{}-\N{e}{}$] is the number of background
  events \emph{with} a valid off-line trigger. This formula is the
  simplest case of one bunch crossing per trigger/background
  class. For more complicated collision setups the fractions in the
  formula change.
\end{description}
The two terms under the parenthesis in \eqref{eq:fulleventnorm} refers
to the observed number of event $\NA$, and the events missed because
of no vertex reconstruction.  Note, for $\beta\ll\NT{}$
%% \eqref{eq:fulleventnorm} 
this reduces to the simpler expression
$$
\N{X}{} = \frac1{\epsilon_X}\frac1{\epsilon_V}\NA{}
$$
The trigger efficiency $\epsilon_X$ for a given trigger type $X$ is
evaluated from simulations as
\begin{align*}
  \epsilon_X = \frac{\N{X\wedge \text{T}}{}}{\N{X}{}}\quad,
\end{align*}
that is, the ratio of number of events of type $X$ with a
corresponding trigger $T$ to the number of events of type $X$.

If the trigger $X$ introduces a bias on the measured number of events,
then \eqref{eq:eventnormdndeta} need to be modified to 
\begin{align}
  \ndndeta &= 
  \frac{\NA}{\N{X}{}}\frac1{\Delta\eta} \int_0^{2\pi} \text{d}\varphi
  \frac{1}{B\etaphi}\frac{\dndetadphi}{\PhiAcc}
  \label{eq:eventnormdndeta2}\quad,
\end{align}
where $B\etaphi$ is the bias correction.  This is typically
calculated from simulations using the expression 
\begin{align*}
  B\etaphi = \frac{\frac{1}{\N{X\wedge \text{T}}{}}\sum_i^{\N{X\wedge
        \text{T}}{}}
    \mult[,\text{primary}]\etaphi}{\frac{1}{\N{X}{}}\sum_i^{\N{X}{}}
    \mult[,\text{primary}]\etaphi}
\end{align*}
Note that typically $B\etaphi$ is unity.

%% --- Sub section on the empirical correction -----------------------
\subsection{The Empirical Correction} 
\label{sec:sub:empirical} 

The precision of the simulation based correction for secondary
particle production $\SecMap{}$ depends strongly on the accuracy with
which the material is specified in the simulation.  If there is not
enough or too much material (compared to the actual experiment)
specified in the simulations, we will calculate a too low or to high
value for $\SecMap$.  If the correct amount of material \emph{is}
present, but placed incorrectly, we will have a wrong distribution of
$\SecMap$.  Since there are many parts in the various detectors, some
of which are hard to describe, it is very unlikely that we will ever
reach a high enough accuracy so that $\SecMap$ is not associated with
very large uncertainties.

\begin{figure}[th!bp]
  \centering
  \figinput{satellite}
  \caption{Schematic drawing (not to scale) of the cross-section of
    the \ITS{}, \FMD{}, and \VZERO{} and the midpoints of the
    locations of the nominal and `satellite' interaction points. The
    long--dashed line designates a region of dense material designed
    to absorb all particles except $\mu^{\pm}$. The short-dashed line
    indicates the region of the \ALICE{} \ITS{}, which has dense
    material for its services on the surfaces near \FMD{2} and
    \FMD{3}. The area between \FMD{2}, \FMD{1} and \VZERO{}-A contains
    only the beryllium beam pipe. The dark grey shaded areas denote
    the paths particles would follow from $z=\unit[0]{\text{cm}}$ and
    $z=\unit[225]{\text{cm}}$ to \FMD{2} and \VZERO{}-A such that it
    is evident which material they would traverse
    \cite{Abbas:2013bpa}.}
  \label{fig:satellite_geom}
\end{figure}

\paragraph{Satellite Collisions} 
However, in the \PbPbCol{} running of 2010\footnote{The
  \texttt{LHC10h} period.} we were fortunate that the machine provided
collisions of beams at so--called \emph{satellite} locations.

These collisions happened at
$$
z \approx -187.5, -150, \ldots, -37.5, 37.5, 75, \ldots, 300,
\unit[337.5]{\text{cm}} \quad, 
$$ 
and were a consequence of the so-called `debunching effect'
\cite{maxime}.  Particles produced in these off--nominal interaction
point collisions pass through very different regions of \ALICE{}, as
illustrated in \figref{fig:satellite_geom}.  

As illustrated in \figref{fig:satellite_geom}, particles produced in
collisions at say $z\approx\unit[225]{\text{cm}}$ pass through a lot
less material than particles produced at the nominal interaction
region ($z\approx\unit[0]{\text{cm}}$), and the material they do pass
through is a lot simpler and much better described in the simulations.
This was exploited to produce the \ndndeta{} distributions for
\PbPbCol{} at \usNN{PbPb}{2760} for centrality bins $0-5-10-20-30\%$
\cite{Abbas:2013bpa}.  Another benefit of this approach was the
overlap between the \FMD{} and \VZERO{} acceptance, and that the
\VZERO{} and \FMD{} results could be checked against the results from
the \SPD{} tracklets.

\begin{figure}[h!tbp]
  \centering
  \subfigure[]{
    \label{fig:empirical:cent}\figinput[.45\linewidth]{empirical_cent}}
  \subfigure[]{
    \label{fig:empirical:secmap}\figinput[.45\linewidth]{secmap_empcor}}
  \caption{\subref{fig:empirical:cent} The empirical correction
    $\EmpCor[c]{}$ for 4 centralities, and the mean of these.  The
    lower plot shows the ratio of $\EmpCor[c]{}$ to the mean.  From
    this we see we $\pm2\%$ systematic error on
    $\EmpCor{}$. \subref{fig:empirical:secmap} The average empirical
    correction compared to simulation based
    $\langle\SecMap\rangle=1/2\pi\int\text{d}\varphi\SecMap{}$ for
    given $\IPz{}$ bin. } 
\end{figure}


\paragraph{Nominal interactions} 
We can then turn the argument around to form a new correction for
secondaries.  We perform the inclusive (primaries \emph{and}
secondaries) analysis for the pseudo--rapidity density
(\ndndeta{}$|_{\text{nominal,inclusive}}$) for \PbPbCol{} at
\usNN{PbPb}{2760} at nominal interaction points
($z\in[\unit[-10]{\text{cm}},\unit[+10]{\text{cm}}]$) by turning off
the secondary correction $\SecMap$ (see
\secref{sec:sub:sub:secmap}).The \emph{empirical correction} is then
defined as

\begin{equation}
  \label{eq:empirical:cent}
  \EmpCor[c]{} = \frac{%
    \left.\ndndeta\right|_{\text{nominal,inclusive}}}{%
    \left.\ndndeta\right|_{\text{satellite}}}\quad,
\end{equation}
where the denominator is the result from the satellite \PbPbCol{} at
\usNN{PbPb}{2760} analysis \cite{Abbas:2013bpa}, and the numerator is
the result from collisions at the nominal interaction point
\emph{without} the secondary correction.   The sub-script $c$
indicates that we can form this ratio separately in each of the 4
centrality bins we have satellite results from.  The result can be
seen in \figref{fig:empirical:cent}. 

\paragraph{Stability}
We see that the correction is stable over all centralities and that we
can use the weighted average over all centralities to define 

\begin{equation}
  \label{eq:empirical}
  \EmpCor{} = \frac{\sum_c \Delta c\EmpCor[c]{}}{\sum_c \Delta c}\quad.
\end{equation}

Further motivation for the empirical correction as a correction
for the produced secondary corrections, is found in
\figref{fig:empirical:secmap}.  Here, the simulation based $\SecMap$
is compared to the data driven $\EmpCor$.  We see that $\EmpCor$
follows the shape of $\SecMap$ overall with differences at $\eta<0$
and around $\eta=2$ -- as we would expect from a correction that
depends on the material distribution. 

\begin{figure}[h!tbp]
  \centering
  \subfigure[]{
    \label{fig:empirical:compare_es}\figinput[.55\linewidth]{compare_es}}
  \subfigure[]{
    \label{fig:empirical:es_pp0900}\figinput[.35\linewidth]{es_pp0900}}
  \caption{\subref{fig:empirical:compare_es} Comparison of $\EmpCor$ and
    $\EmpCor[\subIPz,r]{}$.  The spread of $\EmpCor[\subIPz,r]{}$
    reflects the different material seen at different values of
    $\IPz$.   \subref{fig:empirical:es_pp0900} Comparison of applying
    either $\EmpCor$ or $\EmpCor[\subIPz,r]{}$ to \ppCol{} at
    \usNN{pp}{0900}. }
  \label{fig:empirical:methods}
\end{figure}

In principle we could form the ratio of \eqref{eq:empirical:cent} in
separate $\IPz$ bins and separately for each \FMD{} ring.  We would
then apply that correction $\EmpCor[\subIPz,r]{}$ instead of $\SecMap$
as outlined in \secref{sec:sub:sub:secmap}.  A comparison of the two
methods is shown in \figref{fig:empirical:methods}.  We see that the
difference in using either the single correction $\EmpCor$ or the
interaction point, ring dependent correction $\EmpCor[\subIPz,r]{}$ is
less than 2\%.

\begin{figure}[h!tbp]
  \centering
  \figinput[.9\linewidth]{empcor_stable}
  \caption{Stability of $\EmpCor$.  Two groups are clearly seen:
    Before run 138190 and after run 138190.  From the Quality
    Assurance we know that the runs before 138190 are problematic, and
    are therefore not considered. }
  \label{fig:empirical:empcor_stable}
\end{figure}

The empirical correction shown in \figref{fig:empirical:methods} comes
from analysing a single run (138190) to obtain the numerator of
\eqref{eq:empirical:cent}.  To access the stability of the correction
with respect to the reference data, all of the \PbPbCol{} data from
2010 was analysed.  The result is shown in
\figref{fig:empirical:empcor_stable}.  Apart from the problematic runs
before run 138190, the resulting corrections all fall within
$\pm5\%$. 


\paragraph{Universality} The empirical correction $\EmpCor$ as a
correction for secondary particle production is by nature
\emph{universal}.  That is, it can be applied to \emph{any} collision
system and energy since it depends only on the material in \ALICE{}.
Howver, as shown in \figref{fig:secmap:all} there is a residual
uncertainty from the hadron chemistry which especially effects
\FMD{1}.  This forces us to assign a systematic error of the order of
a few percent more in the \FMD{1} region than what we would otherwise
to in the remaining regions. 
\FIXME{Marek, if your studies show we can ignore this, then this
  should be reformulated}


The empirical correction is seen to be stable and known to within
$\pm5\%$.  


\paragraph{The final \ndndeta{}}
We can then apply this correction to the inclusive pseudo--rapidity
density (\indndeta{}) for \emph{any} system and collision energy to
find the \emph{primary} charged particle pseudo--rapidity density

\begin{equation}
  \label{eq:empirical:applied}
  \ndndeta = \frac{1}{\EmpCor{}} \indndeta{}
\end{equation}

\subsection{Systematic Errors}
\label{sec:sub:dndeta:syserr}

\tabref{tab:syserr} summarises the systematic error sources and
sizes. 


\begin{table}[h!tbp]
  \centering
  \caption[Summary of systematic errors]{Summary of systematic
    errors. Errors on the 
    event selection in \ppCol{} are taken from \cite{pwgud:2015}.
    Errors on the centrality selection in \pPbCol{} and \PbpCol{} from
    \cite{Adam:2014qja}.  \PbPbCol{} systematics from
    \cite{PbPbCent:XXX}. \newline
    %% 
    \textsuperscript{*}These
    entries are not directly calculated into the total. \newline
    \textsuperscript{**}These are estimated from the difference to the
    empirical correction.}
  \footnotesize
  \begin{tabular}[t]{|cc|c|cccc|cc|c|}
    \hline
    \headColor%
    \multicolumn{2}{|l|}{\textbf{System}} 
    & Corre- 
    & \multicolumn{4}{c|}{\ppCol{}} 
    & \pPbCol{} 
    & Pb-p 
    & \PbPbCol{}\\
    \headColor%
    \multicolumn{2}{|l|}{\textbf{Source}} 
    & lated 
    & \GeV[900]{}
    & \TeV[2.76]{} 
    & \TeV[7]{}
    & \TeV[8]{}
    & \multicolumn{2}{c|}{\TeV[5.02]{}}
    & \TeV[2.76]{}\\
    \hline
    & \INEL   
    & y 
    & ${}_{-0.1}^{+0.3}\%$ 
    & ${}_{-0.35}^{+0.6}\%$ 
    & ${}_{-0.3}^{+0.6}\%$ 
    & ${}_{-0.3}^{+0.6}\%$ 
    & \multicolumn{2}{c|}{n/a}
    & n/a \\
    \altRowColor \cellcolor{white}
    & \INELGT 
    & y 
    & \multicolumn{4}{c|}{negl.} 
    & \multicolumn{2}{c|}{n/a} 
    & n/a \\
    & \NSD    & y & $\pm2\%$ 
    & $\pm3\%$  
    & $\pm2\%$ 
    & $\pm2\%$ 
    & 1--2\% & 1--2\% & n/a \\
    \altRowColor\cellcolor{white}
    \multirow{-4}{*}{\minitab[c]{\rowcolor{white}Event\\ selection}} 
    & Centrality 
    & y 
    & \multicolumn{4}{c|}{n/a} 
    & 2--4\% 
    & 3--6\% 
    & 1--2\% \\
    \hline 
    & Merging 
    & n 
    & \multicolumn{4}{c|}{1\%} 
    & \multicolumn{2}{c|}{1\%} 
    & 1\%\\ 
    \altRowColor\cellcolor{white}
    \multirow{-2}{*}{Analysis} 
    & Density 
    & n 
    & \multicolumn{4}{c|}{1\%} 
    & \multicolumn{2}{c|}{1\%} 
    & 1\%\\ 
    \hline
    \multicolumn{2}{|c|}{Secondary map\textsuperscript{*}\hspace*{4em}} 
    & n 
    & \multicolumn{7}{c|}{5-15\%\textsuperscript{**}}\\
    \hline
    \altRowColor{}\cellcolor{white} 
    & Satellite\textsuperscript{*} 
    & n 
    & \multicolumn{7}{c|}{3.5-7.5\%} \\
    & Reference\textsuperscript{*}  
    & n 
    & \multicolumn{4}{c|}{4\%} 
    & \multicolumn{2}{c|}{4\%} 
    & 5\%?\\ 
    \altRowColor{}\cellcolor{white} 
    \multirow{-3}{*}{Empirical} 
    & As--applied
    & n 
    & \multicolumn{4}{c|}{6.1\%} 
    & \multicolumn{2}{c|}{6.1\%} 
    & 6.1\%\\ 
    \hline
    \multicolumn{2}{|c|}{Hadron chemistry\hspace*{4em}}
    & n 
    & \multicolumn{4}{c|}{2\%(?)} 
    & \multicolumn{2}{c|}{2\%(?)} 
    & 2\%\\ 
    \hline
    \altRowColor\cellcolor{white}
    &   \INEL{}
    & 
    & \multicolumn{4}{c|}{6.3\% (6.6\%)}
    & \multicolumn{2}{c|}{n/a}
    & n/a 
    \\
    & \INELGT{}
    & 
    & \multicolumn{4}{c|}{6.3\% (6.6\%)}
    & \multicolumn{2}{c|}{n/a}
    & n/a \\
    \altRowColor\cellcolor{white}
    & \NSD{}
    & 
    & \minitab[c]{6.6\%\\(6.9\%)}
    & \minitab[c]{6.9\%\\(7.2\%)}
    & \multicolumn{2}{c|}{\minitab[c]{6.6\%\\(6.9\%)}}
    & \multicolumn{2}{c|}{\minitab[c]{6.6\%\\(6.9\%)}}
    & n/a \\
    \multirow{-4}{*}{Total} 
    & Centrality 
    & 
    & \multicolumn{4}{c|}{n/a} 
    & \minitab[c]{6.6--7.4\%\\(6.9--7.7\%)}
    & \minitab[c]{6.9--8.7\%\\(7.2--8.9\%)}
    & \minitab[c]{6.3--6.6\%\\(6.6--6.9\%)} \\
    \hline
  \end{tabular}
  \label{tab:syserr}
\end{table}

\begin{description}
\item[Event selection] \hbox{}\hfill
  \begin{description}
  \item[\INEL{} \& \NSD{}] The source of this systematic error is
    mainly the estimated error on the trigger selection, as well as
    the estimated error on the vertex reconstruction.  Other sources
    include pile-up.  Of these sources, the most dominant is the
    trigger efficiency and the rest are considered negligible
    \cite{pwgud:2015}.
  \item[\INELGT{}] Since this trigger is purely experimentally defined
    there is not or very small errors associated with the trigger
    efficiency, and the remaining contributions from vertex
    reconstruction and pile-up are negligible \cite{pwgud:2015}.
  \item[Centrality] The ranges given here are from most central (lower
    systematic error) to most peripheral (higher systematic error)
    \cite{Adam:2014qja,PbPbCent:XXX}.
  \end{description}
\item[Analysis] \hbox{}\hfill
  \begin{description}
  \item[Merging] This comes from the process of merging signals that
    are shared over 2 strips (see \secref{sec:sub:sharing_filter}).
    This has been evaluated by varying cuts and cut definitions (see
    \secref{sec:cuts}).
  \item[Density] This comes from the estimation of the inclusive
    number of charge particles per $\etaphi$--bin.  The size of this
    error is estimated by evaluating the correlation between the two
    available methods for obtaining $\dndetadphi[incl,r,\subIPz,i]$
    (see \secref{sec:sub:density_calculator}), and by varying the
    threshold cut and cut definitions (see \secref{sec:cuts}). 
  \end{description}
\item[Secondary map] This row is mainly included for historical
  reasons and apply only in the case where the $\SecMap$ correction is
  applied to the data (see \secref{sec:sub:sub:secmap}). 
\item[Empirical] \hbox{}\hfill 
  \begin{description}
  \item[Satellite] These are the systematic errors from the published
    $\ndndeta$ based on an analysis of satellite collisions
    \cite{Abbas:2013bpa}.  The variation in the number stems from the
    uncertainty in the centrality determination, which presumably
    biases both the denominator and numerator of
    \eqref{eq:empirical:cent} in the same direction. The effect on the
    empirical correction is discussed in \secref{sec:dndeta:sys:emp}. 
  \item[Reference] As shown in \figref{fig:empirical:cent} and
    \ref{fig:empirical:methods} the variation of chosen reference run
    and the choice of method results in a 5\% systematic error. The
    effect on the empirical correction is discussed in
    \secref{sec:dndeta:sys:emp}.
  \item[As--applied] This is the systematic error as applied to the
    data in the this analysis. The error is discussed in
    \secref{sec:dndeta:sys:emp}.
  \end{description}
\item[Hadron Chemistry] An additional 2\% in the \FMD{1} region should
  be added in quadrature and stems from the additional sensitivity to
  the hadron chemistry discussed elsewhere in
  \secref{sec:sub:sub:secmap}.
\FIXME{Note that the systematic error on the empirical correction
  already contain 2-3\% error on this in the FMD region --- see \tabref{tab:satellite:syserrs}.} 
\end{description}

\subsubsection{Systematics error on the Empirical Correction} 
\label{sec:dndeta:sys:emp}

The \ndndeta{} in centrality bins from 0 to 30\% previously published
\cite{Abbas:2013bpa} is based on three measurements: \SPD{} tracklets,
\VZERO{} amplitude match to the \SPD{}, and the \FMD{} signals.  Each
of these measurements carried their own set of systematic errors, as
well as some common ones. \tabref{tab:satellite:syserrs} summarises
the various contributions. 

\begin{table}[htbp]
  \centering
  \caption{The systematic errors of the published \ndndeta{}.  Adapted
    from \cite{Abbas:2013bpa}.}
  \begin{tabular}[T]{|clc|}
    \hline 
    \headColor
    \textbf{Detector} 
    & \textbf{Source} 
    & \textbf{Error}\\ 
    \hline 
    Common 
    & Centrality 
    & 1--2\%\\
    \hline 
    % SPD 
    & Background subtraction   
    & 0.1--2\%\\
    \altRowColor{}\cellcolor{white} % SPD    
    & Particle composition
    & 1\%\\
    % SPD
    & Weak decays 
    & 1\%\\
    \altRowColor{}\cellcolor{white}\multirow{-4}*{\SPD}
    & Extrapolation to $p=0$ 
    & 2\%\\                              
    \hline 
    & Material budget 
    & 4\%\\
    \altRowColor{}\cellcolor{white}
    \multirow{-2}*{\minitab[c]{%
    \cellcolor{white}\FMD{}\\
    \cellcolor{white}\& \VZERO{}}} 
    & ZEM scaling 
    & 4\% \\    
    \hline
    & Particle composition, spectra, weak decays 
    & 2\%\\
    \altRowColor{}\cellcolor{white} 
    & Variation of cuts 
    & 3\%\\
    \multirow{-3}*{\FMD{}} 
    & Analysis method 
    & 2\%\\ 
    \hline
    \altRowColor{}\cellcolor{white} 
    & Variation between rings 
    & 3\%\\
    \multirow{-2}*{\VZERO{}}
    & Calibration by \SPD{} 
    & 3--4\%\\
    \hline 
  \end{tabular}
  \label{tab:satellite:syserrs}
\end{table}

The 3 measurements was then added up using the non--common systematic
errors as weights, and finally the common systematics errors are added
in quadrature.  The result is shown in the top of
\figref{fig:dndeta:sat:results}. Subtracting the common error from the
centrality estimate from the systematic error leaves us with an error
of 7.2\% in the high limit, and 3.6\% in the low limit.
 
\begin{figure}[h!tbp]
  \centering
  \figinput[.8\linewidth]{satellites_dndeta}
  \caption{Top shows the \ndndeta{} from satellite collisions after
    summing the 3 measurements, and adding the common systematics in
    quadrature \cite{Abbas:2013bpa}.  The bottom panel shows the
    result relative systematic error for each centrality bin. For the
    points relevant for the forward analysis we see a variation from
    3.75\% --- for the most central --- up to 7.5\% --- for the most
    peripheral.  The dashed line indicates the centrality weighted
    mean. }
  \label{fig:dndeta:sat:results}
\end{figure}

As outlined in \secref{sec:sub:empirical}, the empirical correction is
formed by averaging over the available centralities 
\begin{equation}
  \EmpCor{} = \frac{\sum_c \Delta c\EmpCor[c]{}}{\sum_c \Delta c}
  \tag{\ref{eq:empirical}}
\end{equation}
where $\EmpCor[c]{}$ is given by \eqref{eq:empirical:cent}.  That
means, we should consider the centrality weighted systematic error (as
shown in \figref{fig:dndeta:sat:results}), and we find a low value of
$\sqrt{4.2^2-1.5^2}=3.9\%$ and a high value of
$\sqrt{4.9^2-1.5^2}=4.7\%$, with an average of
$\sqrt{4.5^2-1.5^2}=4.2$ in the $\eta$ regions relevant for this
analysis. 

The error on the numerator of \eqref{eq:empirical:cent} is given by
the run--to--run variation illustrated in
\figref{fig:empirical:empcor_stable}, and amounts to 4\%.  Adding this
up in quadrature gives the final systematic on the empirical
correction to be 
\begin{align}
  \label{eq:empcorr:syserr}
  \min{\delta\EmpCor{}} &= \sqrt{3.9^2+4^2} = 5.6\%\nonumber\\
  \max{\delta\EmpCor{}} &= \sqrt{4.7^2+4^2} = 6.1\%\nonumber\\
  \langle\delta\EmpCor{}\rangle &= 5.8\%\quad.\\
\end{align}
Considering the overall variation across $\eta$ is relatively small,
we err on the side caution and choose $\delta\EmpCor{}=6.1\%$ for the
systematic error of empirical correction. 


\section{Result plots} 

In the follow sub--section the \ndndeta{} results for some collision
systems will be presented.  Here, only the \PbPbCol{} result is
finalised, and the final results on other systems will be addressed in
follow--up notes.   The common parameters are listed in
\tabref{tab:common:params}. 

\begin{table}
  \caption{Parameters of analysis}
  \centering
  \begin{tabular}[t]{|rlc|}
    \hline
    \headColor{} 
    \textbf{Parameter}
    & \textbf{Description}
    & \textbf{Value}\\
    \hline 
    $\IPz$ 
    & interaction point $z$ 
    & \unit[-10]{cm} -- \unit[+10]{cm}\\
    \altRowColor{}
    $\max{\delta\IPz}$ 
    & Largest $\IPz$ uncertainty 
    & \unit[0.2]{cm}\\
    $\min{N_{\text{pileup,contrib}}}$ 
    & Least number of pile--up contributors 
    & 5\\
    \altRowColor{}
    $\min{d_{\text{pileup}}}$ 
    & Least pile-up distance 
    & \unit[0.8]{cm}\\
    \hline 
    $L_{\text{sharing}}$ 
    & Low sharing cut 
    & 0.15\\
    \altRowColor{}
    $H_{\text{sharing}}$ 
    & High sharing cut 
    & $\Delta_p-1(\xi+\sigma)$ \\
    $T_{\text{poisson}}$ 
    & Poisson threshold 
    & $\Delta_p-1(\xi+\sigma)$ \\
    \altRowColor{}
    $R_{\text{poisson}}$ 
    & Poisson region size 
    & $\unit[4]{sectors} \times \unit[32]{strips}$\\
    \hline 
  \end{tabular}
  \label{tab:PbPb:param}
\end{table}


Each result is accompanied by a summary table of parameters used in
the particular analysis, including the selected runs.  The results are
plotted with individual systematic errors stacked up, and the common
systematic errors split off to the side.  For papers, the format could
be different, and one could consider symmetrisation, averaging with
central points,  and so on. 


\subsection{\PbPbCol{}}

See \tabref{tab:PbPb:params} and \figref{fig:PbPb:results} for results
based on the \texttt{V0M} centrality estimator. 

\begin{table}[h!tbp]
  \caption{Parameters of the \PbPbCol{} $\usNN{PbPb}{2760}$ analysis}
  \centering
  \begin{tabular}[t]{|rlc|}
    \hline
    \headColor{} 
    \textbf{Parameter}
    & \textbf{Description}
    & \textbf{Value}\\
    \hline 
    $\text{CENT}$ 
    & Centrality estimator 
    & \texttt{V0M}\\
    \hline 
    \altRowColor{}
    Runs 
    & \multicolumn{2}{r|}{138190 138225 138469 138666 138872 139038
      139173 139329 139503}\\ 
    \hline
  \end{tabular}
  \label{tab:PbPb:params}
\end{table}
  \FIXME{Central come very soon}
\begin{figure}[h!tbp]
  \centering
  \figinput[\linewidth]{PbPb_2760_CENTV0M}
  \caption{\ndndeta{} result for \PbPbCol{} collisions at
    $\usNN{PbPb}{2760}$ in centrality bins.  Open points are the
    previously published result \cite{Abbas:2013bpa}. Shown are also
    the systematic errors.}
  \label{fig:PbPb:results}
\end{figure}

\subsection{\pPbCol{}}

See \tabref{tab:pPb:params} and \figref{fig:pPb:results} for results
based on the \texttt{ZNA} and \texttt{V0C} centrality estimator. 
\FIXME{V0M, CL1 estimators coming soon}.
\FIXME{Pbp results coming soon}

\begin{table}[h!tbp]
  \caption{Parameters of the \pPbCol{} $\usNN{PbPb}{5023}$ analysis}
  \centering
  \begin{tabular}[t]{|rlc|}
    \hline
    \headColor{} 
    \textbf{Parameter}
    & \textbf{Description}
    & \textbf{Value}\\
    \hline 
    $\text{CENT}$ 
    & Centrality estimator 
    & \texttt{ZNA}\\
    \altRowColor{}
    & 
    & \texttt{V0A}\\
    \hline 
    Runs 
    & \multicolumn{2}{r|}{}\\ 
    \hline
  \end{tabular}
  \label{tab:pPb:params}
\end{table}

\begin{figure}[h!tbp]
  \centering
  \begin{tabular}[T]{@{}c@{}c@{}}
    \figinput[.5\linewidth]{pPb_5023_CENTV0A}
    & \figinput[.5\linewidth]{pPb_5023_CENTZNA}
    \\
  \end{tabular}
  \caption{\ndndeta{} result for \pPbCol{} collisions at
    $\usNN{pPb}{5023}$. Central points from \cite{Adam:2014qja}.} 
  \label{fig:pPb:results}
\end{figure}

\subsection{\ppCol{}}

See \tabref{tab:pp:params} and \figref{fig:pp:results:0900} to
\ref{fig:pp:results:8000} for results for the \INEL{}, \INELGT{},
and \NSD{} event classes.  
\FIXME{\INELGT coming soon}

\begin{table}[h!tbp]
  \caption{Parameters of the \ppCol{} $\usNN{pp}{0900}, 2.76, 7,
    \text{and} \TeV[8]{}$ analysis}
  \centering
  \begin{tabular}[t]{|rlc|}
    \hline
    \headColor{} 
    \textbf{Parameter}
    & \textbf{Description}
    & \textbf{Value}\\
    \hline 
    $\text{TRIG}$ 
    & Trigger
    & \INEL\\
    \altRowColor{}
    & 
    & \INELGT\\
    \hline 
    & 
    & \NSD\\
    \hline 
    \altRowColor{}
    Runs 
    & \multicolumn{2}{r|}{}\\ 
    \hline
  \end{tabular}
  \label{tab:pp:params}
\end{table}

\begin{figure}[h!tbp]
  \centering
  \begin{tabular}[T]{@{}c@{}c@{}}
    \figinput[.5\linewidth]{pp_0900_INEL}
    & \figinput[.5\linewidth]{pp_0900_NSD}
    \\
  \end{tabular}
  \caption{\ndndeta{} result for \ppCol{} collisions at
    $\usNN{pp}{0900}$. Central results from the draft paper
    \cite{pwgud:2015}. Also shown are the previous published results
    \cite{Aamodt:2010ft}}
  \label{fig:pp:results:0900}
\end{figure}
\begin{figure}[h!tbp]
  \centering
  \begin{tabular}[T]{@{}c@{}c@{}}
    \figinput[.5\linewidth]{pp_2760_INEL}
    & \figinput[.5\linewidth]{pp_2760_NSD}
    \\
  \end{tabular}
  \caption{\ndndeta{} result for \ppCol{} collisions at
    $\usNN{pp}{2760}$. Central results from \cite{pwgud:2015}.} 
  \label{fig:pp:results:2760}
\end{figure}
\begin{figure}[h!tbp]
  \centering
  \begin{tabular}[T]{@{}c@{}c@{}}
    \figinput[.5\linewidth]{pp_7000_INEL}
    & \figinput[.5\linewidth]{pp_7000_NSD}
    \\
  \end{tabular}
  \caption{\ndndeta{} result for \ppCol{} collisions at
    $\usNN{pp}{7000}$. Central results from \cite{pwgud:2015}.} 
  \label{fig:pp:results:7000}
\end{figure}
\begin{figure}[h!tbp]
  \centering
  \begin{tabular}[T]{@{}c@{}c@{}}
    \figinput[.5\linewidth]{pp_8000_INEL}
    & \figinput[.5\linewidth]{pp_8000_NSD}
    \\
  \end{tabular}
  \caption{\ndndeta{} result for \ppCol{} collisions at
    $\usNN{pp}{8000}$. Central results from \cite{pwgud:2015}.} 
  \label{fig:pp:results:8000}
\end{figure}


%% === Section on energy loss fits ===================================
\clearpage
\section{$\Delta$ Fits}
\label{sec:fits}

\FIXME{Example plots}
The single particle distribution of energy loss $x$ is best fit with a
Landau folded with a Gaussian \cite{nim:b1:16,phyrev:a28:615}.
\begin{align} 
  \label{eq:f}
 f(x;\Delta_p,\xi,\sigma') = \frac{1}{\sigma' \sqrt{2 \pi}}
 \int_{-\infty}^{+\infty} dx' f'_{L}(x',\Delta_p,\xi)
 e^{-\frac{(x-x')^2}{2\sigma'^2}}\quad,
\end{align}
where $ f'_{L}$ is the Landau distribution, $\Delta_p$ the most
probable energy loss, $ \xi$ the width of the Landau, and $
\sigma'^2=\sigma^2-\sigma_n^2 $.  Here, $\sigma$ is the variance of
the Gaussian, and $\sigma_n$ is a parameter modelling noise in the
detector.

For $i$ particles this is modified to 
\begin{align}
  f_i(x;\Delta_{p},\xi,\sigma')=f(x;\Delta_{p,i},\xi_i,\sigma_i')\quad,
\end{align}
corresponding to $ i$ particles i.e., with the substitutions 
\begin{align*}
  \Delta_p  &\rightarrow \Delta_{p,i} = i\left(\Delta_p + \xi\log(i)\right)\\
  \xi       &\rightarrow \xi_i       = i \xi\\
  \sigma    &\rightarrow \sigma_i    = \sqrt{i}\sigma\\
  \sigma'^2 &\rightarrow \sigma_i'^2 = \sigma_n^2 + \sigma_i^2
\end{align*}

Because of the convolution with a Gaussian, the most-probable-value
$\Delta_p'$ of the resulting distribution is not really at the
Landau most-probable-value $\Delta_p$.  In fact we find that
$\Delta_p' > \Delta_p$.

Ideally, one would find an analytic expression for this shift by
solving
\begin{align*}
  0 &= \frac{\text{d} f_i(x;\Delta_p,\xi,\sigma)}{\text{d}x}\nonumber\\
    &= \frac{\text{d}}{\text{d}x}\frac{1}{\sigma' \sqrt{2 \pi}}
     \int_{-\infty}^{+\infty} dx' f'_{L}(x',\Delta_p,\xi)
     e^{-\frac{(x-x')^2}{2\sigma'^2}}
\end{align*}
for $x$ as a function of $\Delta_p,\xi,\sigma,i$. However,
do to the complex nature of the Landau distribution this is not
really feasible.

Instead, the shift was studied numerically. Landau-Gauss
distributions for $i=1,\ldots$ where generated with varying
$\xi$ and $\sigma$.  The distributions was then numerically
differentiated and the root $\Delta_p'$ of that derivative
found numerically.  The difference
$\delta\Delta_p=\Delta_p'-\Delta_p$ was then studied as a
function of the $\sigma,\xi$ parameters and an approximate
expression was found
\begin{align}
  \delta\Delta_p \approx \frac{c \sigma u}{(1+1/i)^{p u^{3/2}}}
\end{align}
where $ u=\sigma/\xi$.  The parameters $c$ and $p$ is
found to depend on $ u$ only weakly, and for practical
applications where $u\approx1$, we set $ c=p=1/2$. 

For the evaluating the full energy loss distribution from
$1+2+\ldots,n$ particles, we evaluate
\begin{align}
  f_N(x;\Delta_p,\xi,\sigma',\mathbf{a})=\sum_{i=1}^N a_i
  f_i(x;\Delta_p,\xi,\sigma',a)\quad,
\end{align}
where $ f(x;\Delta_p,\xi,\sigma')$ is the convolution of a Landau with
a Gaussian, and $\mathbf{a}$ is a vector of weights for each $
f_i$. Note that $a_1 = 1$.

We fit the function 
$$
F_j(x;C,\Delta_p,\xi,\sigma,\mathbf{a}) = C
f_j(x;\Delta_p,\xi,\sigma',\mathbf{a})
$$
to energy loss distribution for a given $\eta$ bin for a sub-detector
in steps of increasing $j$.  The fit procedure is stopped and
$N_{\text{max}}=j$ when for
$j+1$: 
\begin{itemize}
\item the reduced $\chi^2$ exceeds a certain threshold (usually 20), or
\item the relative error $\delta p/p$ of any parameter of the fit
  exceeds a certain threshold (usually 0.12), or 
\item when the weight $a_j+1$ is smaller than some number (typically
  $10^{-5}$). 
\end{itemize}
The parameters $\Delta_p,\xi,\sigma,$ and $\mathbf{a}$ are stored for
later use in the density calculations (see
\secref{sec:sub:density_calculator}) and to define various cuts on
the energy loss (see \secref{sec:cuts}). 

To estimate the number of charge particles $n_t$ corresponding to a given
energy loss $\Delta_t$ in strip $t$ we can evaluate 
\begin{align}
  n_t &= G_{N_{\text{max}}}(\Delta_t;\Delta_p,\xi,\sigma,\mathbf{a}) =
  \frac{\sum_i^{N_{max}} i\,a_i\,f_i(\Delta_t;\Delta_p,\xi,\sigma)}{
    \sum_i^{N_{max}}\,a_i\,f_i(\Delta_t;\Delta_p,\xi,\sigma)}
  \tag{\ref{eq:nt}}\quad. 
\end{align}

%% === Section on how cuts are defined ===============================
\clearpage
\section{Cuts}
\label{sec:cuts}

\FIXME{Possibly some plots}
Cuts on the energy loss can be defined in 6 ways all with the single
parameter $X$:
\begin{description}
\item[\emph{Fixed value} $c=X$]
  The cut is defined as a hard cut at a particular value $X$.  This
  type of cut is typically used in the sharing filter (see
  \secref{sec:sub:sharing_filter}) for the lower cut.
\item[\emph{Fit range}]
  The cut $c$ is set to the lower bound of the fit range of the energy
  loss fits (see \secref{sec:fits}).  This type of cut is deprecated.
\item[\emph{Fraction of $\Delta_p$} $c=X\Delta_p$] The cut is defined
  as some fraction $X<1$ of the most probably value of obtained in
  the energy loss fits.  Cuts defined this way are not used in the
  analysis. 
\item[\emph{Landau width} $c=\Delta_p-X\xi$] The cut is defined as
  some number (not necessarily integer) Landau widths below the most
  probably value obtained in the energy loss fits. Cuts defined this
  way are not used in the analysis. 
\item[\emph{Landau and Gauss width} $c=\Delta_p - X(\xi+\sigma)$] The
  cut is defined as some number (not necessarily integer) Landau and
  Gaussian widths below the most probably value obtained in the energy
  loss fits. This type of cuts is typically used in the sharing filter
  (see \secref{sec:sub:sharing_filter}) for the high cut, and in the
  density calculations (see \secref{sec:sub:density_calculator}) for
  the `hit' threshold.
\item[\emph{Probability} $c:P(x<c)<X$] The cut $c$ is defined as
  the largest value for which 
  \begin{align*}
    P(x<c) &= \int_0^c\text{d}x f(x;\Delta_p;\xi;\sigma) < X\quad.
  \end{align*}
  Although mathematically sound, it is slow to compute and adds very
  little in terms of signal quality over the \emph{Landau and Gauss
    width}  cut type.  It is not used in the analysis.
\end{description}
In the above $\Delta_p,\xi,\sigma,$ and $\mathbf{a}$ refers to the
parameters obtained in the energy loss fits (see \secref{sec:fits}),
and $f$ is defined in \eqref{eq:f}.




%% === The bibliography ==============================================
\begin{thebibliography}{99}
  %\cite{Abbas:2013bpa}
\bibitem{Abbas:2013bpa} E.~Abbas {\it et al.}  [ALICE Collaboration],
  ``Centrality dependence of the pseudorapidity density distribution
  for charged particles in \PbPbCol{} collisions at
  \usNN{PbPb}{2760},'' Phys.\ Lett.\ B {\bf 726} (2013) 610
  [arXiv:1304.0347 [nucl-ex]],
  \href{https://aliceinfo.cern.ch/ArtSubmission/node/143}{CERN-PH-EP-2013-045}.
  %%CITATION = ARXIV:1304.0347;%%
  %22 citations counted in INSPIRE as of 03 Sep 2014
\bibitem{oldnote} H.H.~Dalsgaard \and C.H.~Christensen, ``Analysing
  the FMD data for \ndndeta{}'',
  \href{https://aliceinfo.cern.ch/Notes/node/107}{ALICE-ANA-412}
  (2012)
\bibitem{spdnote} R.~Shahoyan, ``Determination of \dndeta{} in
  \PbPbCol{} collision at \unit[2.76]{ATeV} with \SPD{} tracklets'',
  \href{https://aliceinfo.cern.ch/Notes/node/59/}{ALICE-INT-137}
  (2012)
\bibitem{FWD:2004mz} \ALICE{} Collaboration, Bearden, I.~G.\
  \textit{et al} \textit{ALICE technical design report on forward
    detectors: FMD, T0 and V0}, \CERN{}, 2004, CERN-LHCC-2004-025
\bibitem{cholm:2009} C.H.~Christensen, \textit{The ALICE Forward
    Multiplicity Detector --- From Design to Installation},
  Ph.D.~thesis, University of Copenhagen, 2009,
  \url{http://www.nbi.dk/~cholm/}.
\bibitem{maxime} M.~Guilbaud \textit{et al}, \textit{Measurement of
    the charged-particle multiplicity density at forward rapidity with
    ALICE VZERO detector in central Pb-Pb collision at
    $\usNN{PbPb}{2760}$}, ALICE internal note, 2012,
  \url{https://aliceinfo.cern.ch/Notes/node/17/}.
\bibitem{nim:b1:16}
%% \bibitem{Hancock:1983ry}
  S.~Hancock, F.~James, J.~Movchet {\it et al.}, ``Energy Loss
  Distributions For Single Particles And Several Particles In A Thin
  Silicon Absorber,'' Nucl.\ Instrum.\ Meth.\ \textbf{B1} (1984) 16,
  \url{http://cdsweb.cern.ch/record/147286/files/cer-000058451.pdf}.
\bibitem{phyrev:a28:615} 
  %% \bibitem{Hancock:1983fp}
  S.~Hancock, F.~James, J.~Movchet {\it et al.}, ``Energy Loss And
  Energy Straggling Of Protons And Pions In The Momentum Range
  0.7-gev/c To 115-gev/c,'' Phys.\ Rev.\ \textbf{A28} (1983) 615,
  \url{http://cdsweb.cern.ch/record/145395/files/PhysRevA.28.615.pdf}.
\bibitem{hhd:2009} H.H.~Dalsgaard, \textit{Pseudorapidity Densities
    in p+p and Pb+Pb collisions at LHC measured with the ALICE
    experiment}, Ph.D.~thesis, University of Copenhagen, 2011,
  \url{http://www.nbi.dk/~canute/thesis.pdf}.
\bibitem{pwgud:2015} \ALICE{} Collaboration, ``Charged--particle
  multiplicities in proton–-proton collisions at $\sqrt{s} = 0.9$ to
  \TeV[8]{}, with ALICE at the LHC'', draft paper,
  \url{https://aliceinfo.cern.ch/ArtSubmission/node/228}
\bibitem{Aamodt:2010ft}
  K.~Aamodt {\it et al.}  [ALICE Collaboration],
  ``Charged-particle multiplicity measurement in proton-proton collisions at $\sqrt{s}=0.9$ and 2.36 TeV with ALICE at LHC,''
  \textit{Eur.Phys.J.} \textbf{C68} (2010) 89, 
  \href{http://arxiv.org/abs/1004.3034}{arXiv:1004.3034 [hep-ex]},
  \url{http://aliceinfo.cern.ch/ArtSubmission/node/56} 
\bibitem{Adam:2014qja}
  J.~Adam {\it et al.}  [\ALICE{} Collaboration],
  ``Centrality dependence of particle production in p-Pb collisions at
  $\usNN{pPb}{5023}$,'',
  \href{http://arxiv.org/abs/1412.6828}{arXiv:1412.6828 [nucl-ex]}, 
  \url{https://aliceinfo.cern.ch/ArtSubmission/node/1155}
\bibitem{PbPbCent:XXX}
  \ALICE{} Collaboration, ``Centrality determination in \PbPbCol{}'',
  \textbf{{\color{alicered} Need reference}}
\end{thebibliography}

\appendix 
\cleardoublepage
\section{Nomenclature} 
\label{app:nomen}

\begin{table}[hbp]
  \centering  
  \caption{Nomenclature used in this document}
  \small
  \begin{tabular}[t]{|lp{.8\textwidth}|}
    \hline 
    \textbf{Symbol}&\textbf{Description}\\
    \hline 
    \INEL & In--elastic event\\ 
    \INELONE & In--elastic event with at least one tracklet in the
    \SPD{} in the region $-1\le\eta\le1$\\ 
    \NSD{} & Non--single--diffractive event.  Single diffractive
    events are events where one of the incident collision systems
    (proton or nucleus) is excited and radiates particles, but there
    is no other processes taking place\\ 
    \hline
    $\NT{}$ & Number of events with a valid trigger\\
    $\NV{}$ & Number of events with a valid trigger \emph{and} a valid
    vertex.\\  
    $\NA{}$ & Number of events with a valid trigger
    \emph{and} a valid vertex \emph{within} the selected vertex range.\\ 
    $\N{a,c,ac,e}{}$ & Number of events with background triggers $A$,
    $B$, $AC$, or $E$, \emph{and} a valid off-line trigger of the
    considered type.   Background triggers are typically flagged with
    the trigger words \texttt{CINT1-A},  \texttt{CINT1-C},
    \texttt{CINT1-AC}, \texttt{CINT1-E}, or similar.\\
    \hline
    $\mult{}$ & Charged particle multiplicity\\ 
    $\mult[,\text{primary}]$ & Primary charged particle multiplicity
    as given by simulations\\ 
    $\mult[,\text{\FMD{}}]$ & Number of charged particles that hit the
    \FMD{} as given by simulations\\ 
    $n_t$ & Number of charged particles in an \FMD{} strip as
    given by evaluating the energy response functions $G$\\ 
    \hline
    $F$ & Energy response function (see \secref{sec:fits})\\
    $\Delta_{p}$ & Most probably energy loss\\ 
    $\xi$ & `Width' parameter of a Landau distribution\\
    $\sigma$ & Variance of a Gaussian distribution\\ 
    $a_i$ & Relative weight of the $i$--fold MIP peak in the energy
    loss spectra.\\ 
    \hline
    $\Corners{}$ & Azimuthal acceptance of strip $t$\\ 
    $\SecMap{}$ & Secondary particle correction factor in $\etaphi$
    for a given interaction point $\IPz$\\  
    $\DeadCh{}$ & Acceptance in $\etaphi$ for a given interaction point $\IPz$\\ 
    \hline
    $\dndetadphi[incl,r,\subIPz,i]$ & Inclusive (primary \emph{and}
    secondary) charge particle density in event $i$ with interaction
    point $\IPz$, 
    for \FMD{} ring $r$.\\ 
    $\dndetadphi[r,\subIPz,i]$ & Primary charged particle
    density in event $i$ with interaction point $\IPz$ for \FMD{} ring $r$. \\
    $\dndetadphi[\subIPz,i]$ & Primary charged particle density in event $i$
    with interaction point $\IPz$\\  
    $\phiAcc$ & $\varphi$ acceptance in $\eta$ bin for event $i$\\
    $\etaCov$ & $\eta$ coverage of event $i$\\ 
    $\PhiAcc$ & Integrated $\eta$ acceptance over $\NA$ events.
    Note, that this has a value of $\NA$ for $(\eta)$ bins where we
    have full coverage\\ 
    \hline 
    $X_t$ & Value $X$ for strip number $t$ (0-511 for inner rings,
    0-255 for outer rings)\\ 
    $X_r$ & Value $X$ for ring $r$ (where rings are \FMD{1i},
    \FMD{2i}, \FMD{2o}, \FMD{3o}, and \FMD{3i} in decreasing $\eta$
    coverage).\\ 
    $X_{\subIPz}$ & Value $X$ for interaction point $\IPz$ (typically 10 bins from -10cm
    to +10cm)\\ 
    $X_i$ & Value $X$ for event $i$\\
    \hline
  \end{tabular}
  \label{tab:nomenclature}
\end{table}

\end{document}
%% Local Variables:
%%   ispell-dictionary: "british"
%% End:
%% 
%  LocalWords:  tracklets azimuthal outlier tracklet azimuthally FMD
%  LocalWords:  pulser pre OCDB AliFMDSharingFilter algo GetHighCut
%  LocalWords:  radians systematics debunching centralities
%  LocalWords:  pseudorapidity
